{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba9722f3-3412-471d-bb67-b018f5d5ef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to resume_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Loads the PDF file and extracts text.\"\"\"\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            text = ''\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text()  # Concatenate text from all pages\n",
    "        return text\n",
    "\n",
    "def parse_resume_text(text):\n",
    "    \"\"\"Parses the extracted text to extract key information.\"\"\"\n",
    "    # Initialize a dictionary to store parsed data\n",
    "    parsed_data = {\n",
    "        \"contact\": {\n",
    "            \"email\": None,\n",
    "            \"phone\": None\n",
    "        },\n",
    "        \"education\": [],\n",
    "        \"experience\": [],\n",
    "        \"skills\": [],\n",
    "        \"projects\": [],\n",
    "        \"certifications\": []\n",
    "    }\n",
    "\n",
    "    # Extract contact information (email and phone)\n",
    "    email_match = re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text)\n",
    "    if email_match:\n",
    "        parsed_data[\"contact\"][\"email\"] = email_match.group(0)\n",
    "\n",
    "    phone_match = re.search(r\"(\\+?\\d{10,15})\", text)\n",
    "    if phone_match:\n",
    "        parsed_data[\"contact\"][\"phone\"] = phone_match.group(0)\n",
    "\n",
    "    # Extract education details (typically starts with the keyword \"Education\")\n",
    "    education_pattern = re.compile(r\"(Education|Academic Qualifications|Educational Background)(.*?)(?=(Experience|Skills|Projects|Certifications|$))\", re.DOTALL | re.IGNORECASE)\n",
    "    education_matches = education_pattern.findall(text)\n",
    "    for match in education_matches:\n",
    "        parsed_data[\"education\"].append(match[1].strip())\n",
    "\n",
    "    # Extract experience details (typically starts with the keyword \"Experience\")\n",
    "    experience_pattern = re.compile(r\"(Experience|Work Experience)(.*?)(?=(Skills|Education|Projects|Certifications|$))\", re.DOTALL | re.IGNORECASE)\n",
    "    experience_matches = experience_pattern.findall(text)\n",
    "    for match in experience_matches:\n",
    "        parsed_data[\"experience\"].append(match[1].strip())\n",
    "\n",
    "    # Extract skills section (usually starts with \"Skills\")\n",
    "    skills_pattern = re.compile(r\"(Skills|Technical Skills)(.*?)(?=(Experience|Education|Projects|Certifications|$))\", re.DOTALL | re.IGNORECASE)\n",
    "    skills_matches = skills_pattern.findall(text)\n",
    "    for match in skills_matches:\n",
    "        parsed_data[\"skills\"].append(match[1].strip())\n",
    "\n",
    "    # Extract projects section (usually starts with \"Projects\")\n",
    "    projects_pattern = re.compile(r\"(Projects|Personal Projects|Project Experience)(.*?)(?=(Experience|Education|Skills|Certifications|$))\", re.DOTALL | re.IGNORECASE)\n",
    "    projects_matches = projects_pattern.findall(text)\n",
    "    for match in projects_matches:\n",
    "        parsed_data[\"projects\"].append(match[1].strip())\n",
    "\n",
    "    # Extract certifications section (usually starts with \"Certifications\")\n",
    "    certifications_pattern = re.compile(r\"(Certifications|Certifications and Training)(.*?)(?=(Experience|Education|Skills|Projects|$))\", re.DOTALL | re.IGNORECASE)\n",
    "    certifications_matches = certifications_pattern.findall(text)\n",
    "    for match in certifications_matches:\n",
    "        parsed_data[\"certifications\"].append(match[1].strip())\n",
    "\n",
    "    # Return the parsed data\n",
    "    return parsed_data\n",
    "\n",
    "def create_dataframe(parsed_data):\n",
    "    \"\"\"Converts parsed data into a DataFrame.\"\"\"\n",
    "    # Create a DataFrame from the parsed data\n",
    "    df = pd.DataFrame({\n",
    "        \"Contact Email\": [parsed_data[\"contact\"][\"email\"]],\n",
    "        \"Contact Phone\": [parsed_data[\"contact\"][\"phone\"]],\n",
    "        \"Education\": [\", \".join(parsed_data[\"education\"])],\n",
    "        \"Experience\": [\", \".join(parsed_data[\"experience\"])],\n",
    "        \"Skills\": [\", \".join(parsed_data[\"skills\"])],\n",
    "        \"Projects\": [\", \".join(parsed_data[\"projects\"])],\n",
    "        \"Certifications\": [\", \".join(parsed_data[\"certifications\"])]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def save_to_csv(df, file_name=\"resume_data.csv\"):\n",
    "    \"\"\"Saves the DataFrame to a CSV file.\"\"\"\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"resume.pdf\"  # Replace with the actual file path\n",
    "text = load_pdf(file_path)\n",
    "parsed_data = parse_resume_text(text)\n",
    "df = create_dataframe(parsed_data)\n",
    "\n",
    "# Save to CSV\n",
    "save_to_csv(df, \"resume_data.csv\")  # You can specify a different name if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe9a56b-0310-490f-9d8a-dfc0353c6c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Keywords: {'scalable', 'a', 'in', 'backend', 'skills', 'aws', 'java', 'with', 'experience', 'python', 'for', 'developer', 'and', 'react', 'applications'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Loads the PDF file and extracts text.\"\"\"\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            text = ''\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text()  # Concatenate text from all pages\n",
    "        return text\n",
    "\n",
    "def extract_keywords(text):\n",
    "    \"\"\"Extracts keywords (important terms) from a given text.\"\"\"\n",
    "    # Remove non-alphabetic characters and split text into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return set(words)\n",
    "\n",
    "def match_keywords(resume_keywords, job_description_keywords):\n",
    "    \"\"\"Matches keywords from the resume with the job description.\"\"\"\n",
    "    common_keywords = resume_keywords.intersection(job_description_keywords)\n",
    "    return common_keywords\n",
    "\n",
    "# Example usage:\n",
    "resume_file_path = \"My Resume.pdf\"\n",
    "job_description = \"\"\"\n",
    "    We are looking for a backend developer with strong experience in Java, Python, react and MySQL.\n",
    "    Familiarity with AWS is a plus. Excellent problem-solving skills and experience in developing scalable applications are required.\n",
    "\"\"\"\n",
    "\n",
    "# Load and parse the resume\n",
    "resume_text = load_pdf(resume_file_path)\n",
    "\n",
    "# Extract keywords from both the resume and job description\n",
    "resume_keywords = extract_keywords(resume_text)\n",
    "job_description_keywords = extract_keywords(job_description)\n",
    "\n",
    "# Find the common keywords\n",
    "common_keywords = match_keywords(resume_keywords, job_description_keywords)\n",
    "\n",
    "print(f\"Common Keywords: {common_keywords}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca7cb79-416e-41e3-93da-d85dfd751bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resumeee_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Loads the PDF file and extracts text.\"\"\"\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            text = ''\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text()  # Concatenate text from all pages\n",
    "        return text\n",
    "\n",
    "def parse_resume_text(text):\n",
    "    \"\"\"Parses the extracted text to extract key information.\"\"\"\n",
    "    parsed_data = {\n",
    "        \"contact\": {\n",
    "            \"email\": None,\n",
    "            \"phone\": None\n",
    "        },\n",
    "        \"education\": [],\n",
    "        \"experience\": [],\n",
    "        \"skills\": [],\n",
    "        \"projects\": [],\n",
    "        \"certifications\": []\n",
    "    }\n",
    "\n",
    "    # Extract contact information (email and phone)\n",
    "    email_match = re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text)\n",
    "    if email_match:\n",
    "        parsed_data[\"contact\"][\"email\"] = email_match.group(0)\n",
    "\n",
    "    phone_match = re.search(r\"(\\+?\\d{10,15})\", text)\n",
    "    if phone_match:\n",
    "        parsed_data[\"contact\"][\"phone\"] = phone_match.group(0)\n",
    "\n",
    "    # Extract education details\n",
    "    education_pattern = re.compile(r\"(Education|Academic Qualifications|Educational Background)(.*?)(?=(Experience|Skills|Projects|Certifications|$))\", re.DOTALL | re.IGNORECASE)\n",
    "    education_matches = education_pattern.findall(text)\n",
    "    for match in education_matches:\n",
    "        parsed_data[\"education\"].append(match[1].strip())\n",
    "\n",
    "    # Extract experience details\n",
    "    experience_pattern = re.compile(r\"(Experience|Work Experience)(.*?)(?=(Skills|Education|Projects|Certifications|$))\", re.DOTALL | re.IGNORECASE)\n",
    "    experience_matches = experience_pattern.findall(text)\n",
    "    for match in experience_matches:\n",
    "        parsed_data[\"experience\"].append(match[1].strip())\n",
    "\n",
    "    # Extract skills section\n",
    "    skills_pattern = re.compile(r\"(Skills|Technical Skills)(.*?)(?=(Experience|Education|Projects|Certifications|$))\", re.DOTALL | re.IGNORECASE)\n",
    "    skills_matches = skills_pattern.findall(text)\n",
    "    for match in skills_matches:\n",
    "        parsed_data[\"skills\"].append(match[1].strip())\n",
    "\n",
    "    # Extract projects section\n",
    "    projects_pattern = re.compile(r\"(Projects|Personal Projects|Project Experience)(.*?)(?=(Experience|Education|Skills|Certifications|$))\", re.DOTALL | re.IGNORECASE)\n",
    "    projects_matches = projects_pattern.findall(text)\n",
    "    for match in projects_matches:\n",
    "        parsed_data[\"projects\"].append(match[1].strip())\n",
    "\n",
    "    # Extract certifications section\n",
    "    certifications_pattern = re.compile(r\"(Certifications|Certifications and Training)(.*?)(?=(Experience|Education|Skills|Projects|$))\", re.DOTALL | re.IGNORECASE)\n",
    "    certifications_matches = certifications_pattern.findall(text)\n",
    "    for match in certifications_matches:\n",
    "        parsed_data[\"certifications\"].append(match[1].strip())\n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "def create_dataframe(parsed_data):\n",
    "    \"\"\"Converts parsed data into a DataFrame.\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        \"Contact Email\": [parsed_data[\"contact\"][\"email\"]],\n",
    "        \"Contact Phone\": [parsed_data[\"contact\"][\"phone\"]],\n",
    "        \"Education\": [\", \".join(parsed_data[\"education\"])],\n",
    "        \"Experience\": [\", \".join(parsed_data[\"experience\"])],\n",
    "        \"Skills\": [\", \".join(parsed_data[\"skills\"])],\n",
    "        \"Projects\": [\", \".join(parsed_data[\"projects\"])],\n",
    "        \"Certifications\": [\", \".join(parsed_data[\"certifications\"])]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def save_to_csv(df, file_name=\"resume_data.csv\"):\n",
    "    \"\"\"Saves the DataFrame to a CSV file.\"\"\"\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "def evaluate_candidate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Evaluates how well a candidate's skills match the required skills.\"\"\"\n",
    "    # Join the list of candidate skills into a single string\n",
    "    candidate_skills_str = \", \".join(candidate_skills).lower()\n",
    "    \n",
    "    # Convert the required skills to a lower case string and split by commas\n",
    "    required_skill_set = set(required_skills.lower().split(\", \"))\n",
    "    \n",
    "    # Match the candidate's skills with the required skills\n",
    "    candidate_skill_set = set(candidate_skills_str.split(\", \"))\n",
    "    \n",
    "    matched_skills = candidate_skill_set.intersection(required_skill_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_skill_set)) * 100\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"science-cs-egr-resumes-7.pdf\"  # Replace with the actual file path\n",
    "required_skills = \"Java, Python, MySQL, React, Django, JavaScript, HTML, CSS\"  # Example required skills for the position\n",
    "\n",
    "# Load and parse the resume\n",
    "text = load_pdf(file_path)\n",
    "parsed_data = parse_resume_text(text)\n",
    "df = create_dataframe(parsed_data)\n",
    "\n",
    "# Evaluate the candidate's skills against the required skills\n",
    "matched_skills, match_percentage = evaluate_candidate_skills(parsed_data[\"skills\"], required_skills)\n",
    "\n",
    "# Print the match details\n",
    "print(f\"Matched Skills: {matched_skills}\")\n",
    "print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "# Save candidate data to CSV\n",
    "save_to_csv(df, \"resumeee_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b618d18d-5172-4262-99c9-2cf61c0bbe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_dataa.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import csv\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            return ''.join(page.extract_text() for page in pdf.pages)\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    # Match the Skills section and extract its content\n",
    "    skills_match = re.search(r\"(?i)(TECHNICAL SUMMARY|SKILLS)\\s*(.*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        # Clean and split the skills\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[,;/\\n]+\", skills_text)\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])  # Clean and normalize skills\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        # Remove descriptors like \"(Proficient)\" or \"(Familiar)\" and extra text\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", skill).strip()\n",
    "        # Split compound entries like \"Java, Python\" into separate skills\n",
    "        cleaned.extend(re.split(r\"[:,;/]+\", cleaned_skill))\n",
    "        \"\"\"\n",
    "        if '/' in cleaned_skill:\n",
    "            cleaned.extend(cleaned_skill.split('/'))\n",
    "        else:\n",
    "            cleaned.append(cleaned_skill)  \"\"\"\n",
    "    # Return a clean, deduplicated list with all skills in lowercase\n",
    "    return list(set(skill.strip().lower() for skill in cleaned if skill.strip()))\n",
    "\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\"\n",
    ", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    return {key: (value.group(0) if value else \"Not available\") if key != \"skills\" else value for key, value in data.items()}\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_dataa.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    with open(file_name, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(data.keys())  # Write headers\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    if not candidate_skills or not required_skills:\n",
    "        return set(), 0  # No skills to evaluate\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = candidate_set.intersection(required_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    return matched_skills, match_percentage\n",
    "# Example usage:\n",
    "file_path = \"science-cs-egr-resumes-8.pdf\"  # Replace with the actual file path\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Load and parse the resume\n",
    "text = load_pdf(file_path)\n",
    "data = extract_info(text)\n",
    "\n",
    "# Evaluate candidate skills\n",
    "matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "# Debugging extracted text\n",
    "#print(\"Extracted Text:\")\n",
    "#print(text)\n",
    "\n",
    "# Debugging extracted skills\n",
    "#print(\"Extracted Skills:\")\n",
    "#print(data[\"skills\"])\n",
    "\n",
    "# Output the matched skills and percentage\n",
    "print(f\"Matched Skills: {matched_skills}\")\n",
    "print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "# Save extracted data to CSV\n",
    "save_to_csv(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2075a392-6e3a-45d4-bac1-65858e930fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing computer-science-resume-example.pdf...\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing John Doe.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing My Resume.pdf...\n",
      "Matched Skills: {'python', 'java', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing Resume-Sample-2.pdf...\n",
      "Matched Skills: {'java', 'html'}\n",
      "Skill Match Percentage: 25.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resume1.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resume12.pdf...\n",
      "Matched Skills: {'java', 'django', 'python'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resume2.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resume3.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing sample-resumes_scs-3.pdf...\n",
      "Matched Skills: {'java', 'django', 'css', 'python'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing sample-resumes_scs-5.pdf...\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing sample-resumes_scs-6.pdf...\n",
      "Matched Skills: {'django', 'javascript', 'sql', 'java', 'python'}\n",
      "Skill Match Percentage: 62.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing science-cs-egr-resumes-5.pdf...\n",
      "Matched Skills: {'javascript'}\n",
      "Skill Match Percentage: 12.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing science-cs-egr-resumes-8.pdf...\n",
      "Matched Skills: {'java', 'django', 'python', 'html'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Data saved to resume_data1.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            return ''.join(page.extract_text() for page in pdf.pages)\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    # Match the Skills section and extract its content\n",
    "    skills_match = re.search(r\"SKILLS\\s*(.*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        # Clean and split the skills\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)  # Split by bullet points, newlines, or commas\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])  # Clean and normalize skills\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        # Remove descriptors like \"(Proficient)\" or \"(Familiar)\" and extra text\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", skill).strip()\n",
    "        # Split compound entries like \"Java, Python\" into separate skills\n",
    "        cleaned.extend(re.split(r\"[:,;/]+\", cleaned_skill))\n",
    "    # Return a clean, deduplicated list\n",
    "    return list(set(skill.strip().lower() for skill in cleaned if skill.strip()))\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    return {key: (value.group(0) if value else \"Not available\") if key != \"skills\" else value for key, value in data.items()}\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:  # Check if file is empty to write headers\n",
    "            writer.writerow(data.keys())  # Write headers\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = candidate_set.intersection(required_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "def process_pdf_files_in_directory(directory_path, required_skills):\n",
    "    \"\"\"Processes all PDF files in the given directory.\"\"\"\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "            \n",
    "            # Load and parse the resume\n",
    "            text = load_pdf(file_path)\n",
    "            data = extract_info(text)\n",
    "\n",
    "            # Evaluate candidate skills\n",
    "            matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "            # Debugging extracted text\n",
    "            #print(\"Extracted Text:\")\n",
    "            #print(text)\n",
    "\n",
    "            # Debugging extracted skills\n",
    "            #print(\"Extracted Skills:\")\n",
    "            #print(data[\"skills\"])\n",
    "\n",
    "            # Output the matched skills and percentage\n",
    "            print(f\"Matched Skills: {matched_skills}\")\n",
    "            print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "            # Save extracted data to CSV\n",
    "            save_to_csv(data)\n",
    "\n",
    "# Example usage:\n",
    "directory_path = \"resumes\"  # Replace with the directory containing your PDF files\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process all PDF files in the directory\n",
    "process_pdf_files_in_directory(directory_path, required_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de54a210-e68b-4ebd-a6fe-081593b9c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing computer-science-resume-example.pdf...\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing John Doe.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing My Resume.pdf...\n",
      "Matched Skills: {'python', 'java', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing Resume-Sample-2.pdf...\n",
      "Matched Skills: {'java', 'html'}\n",
      "Skill Match Percentage: 25.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resume1.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resume12.pdf...\n",
      "Matched Skills: {'java', 'django', 'python'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resume2.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resume3.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing sample-resumes_scs-3.pdf...\n",
      "Matched Skills: {'java', 'django', 'css', 'python'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing sample-resumes_scs-5.pdf...\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing sample-resumes_scs-6.pdf...\n",
      "Matched Skills: {'django', 'javascript', 'sql', 'java', 'python'}\n",
      "Skill Match Percentage: 62.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing science-cs-egr-resumes-5.pdf...\n",
      "Matched Skills: {'javascript'}\n",
      "Skill Match Percentage: 12.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing science-cs-egr-resumes-8.pdf...\n",
      "Matched Skills: {'java', 'django', 'python', 'html'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Data saved to resume_data1.csv\n",
      "\n",
      "Ranking Candidates:\n",
      "1. mackcrol@gmail.com - 62.50% Match\n",
      "2. mtrix@andrew.cmu.edu - 50.00% Match\n",
      "3. msmith@smith.edu - 50.00% Match\n",
      "4. bellatrevino@email.com - 37.50% Match\n",
      "5. ravigupta.2140@gmail.com - 37.50% Match\n",
      "6. ajaybkedare@gmail.com - 37.50% Match\n",
      "7. uxsi@gmail.com - 37.50% Match\n",
      "8. cindylou@nova.edu - 25.00% Match\n",
      "9. c1phan@smith.edu - 12.50% Match\n",
      "10. john.doe@example.com - 0.00% Match\n",
      "11. emily.williams@example.com - 0.00% Match\n",
      "12. jane.smith@example.com - 0.00% Match\n",
      "13. alex.johnson@example.com - 0.00% Match\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            return ''.join(page.extract_text() for page in pdf.pages)\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    skills_match = re.search(r\"SKILLS\\s*(.*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", skill).strip()\n",
    "        cleaned.extend(re.split(r\"[:,;/]+\", cleaned_skill))\n",
    "    return list(set(skill.strip().lower() for skill in cleaned if skill.strip()))\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    return {key: (value.group(0) if value else \"Not available\") if key != \"skills\" else value for key, value in data.items()}\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow(data.keys())  # Write headers\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = candidate_set.intersection(required_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "def process_pdf_files_in_directory(directory_path, required_skills):\n",
    "    \"\"\"Processes all PDF files in the given directory.\"\"\"\n",
    "    candidates = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "            \n",
    "            # Load and parse the resume\n",
    "            text = load_pdf(file_path)\n",
    "            data = extract_info(text)\n",
    "\n",
    "            # Evaluate candidate skills\n",
    "            matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "            # Debugging extracted text\n",
    "           # print(\"Extracted Text:\")\n",
    "            #print(text)\n",
    "\n",
    "            # Debugging extracted skills\n",
    "           # print(\"Extracted Skills:\")\n",
    "           # print(data[\"skills\"])\n",
    "\n",
    "            # Output the matched skills and percentage\n",
    "            print(f\"Matched Skills: {matched_skills}\")\n",
    "            print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "            # Store the candidate data with match percentage for ranking\n",
    "            candidate_data = data.copy()\n",
    "            candidate_data[\"match_percentage\"] = match_percentage\n",
    "            candidates.append(candidate_data)\n",
    "\n",
    "            # Save extracted data to CSV\n",
    "            save_to_csv(data)\n",
    "\n",
    "    # Rank candidates based on match percentage\n",
    "    ranked_candidates = sorted(candidates, key=lambda x: x[\"match_percentage\"], reverse=True)\n",
    "\n",
    "    print(\"\\nRanking Candidates:\")\n",
    "    for i, candidate in enumerate(ranked_candidates, start=1):\n",
    "        print(f\"{i}. {candidate.get('email', 'No Email')} - {candidate['match_percentage']:.2f}% Match\")\n",
    "\n",
    "    return ranked_candidates\n",
    "\n",
    "# Example usage:\n",
    "directory_path = \"resumes\"  # Replace with the directory containing your PDF files\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process all PDF files in the directory\n",
    "ranked_candidates = process_pdf_files_in_directory(directory_path, required_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b3ee503-bcaf-4c7e-9bdc-9d502d4d6fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing computer-science-resume-example.pdf...\n",
      "Processing John Doe.pdf...\n",
      "Processing My Resume.pdf...\n",
      "Processing Resume-Sample-2.pdf...\n",
      "Processing resume1.pdf...\n",
      "Processing resume12.pdf...\n",
      "Processing resume2.pdf...\n",
      "Processing resume3.pdf...\n",
      "Processing sample-resumes_scs-3.pdf...\n",
      "Processing sample-resumes_scs-5.pdf...\n",
      "Processing sample-resumes_scs-6.pdf...\n",
      "Processing science-cs-egr-resumes-5.pdf...\n",
      "Processing science-cs-egr-resumes-8.pdf...\n",
      "\n",
      "Ranking Candidates:\n",
      "1. mackcrol@gmail.com - 62.50% Match\n",
      "2. mtrix@andrew.cmu.edu - 50.00% Match\n",
      "3. msmith@smith.edu - 50.00% Match\n",
      "4. bellatrevino@email.com - 37.50% Match\n",
      "5. ravigupta.2140@gmail.com - 37.50% Match\n",
      "6. ajaybkedare@gmail.com - 37.50% Match\n",
      "7. uxsi@gmail.com - 37.50% Match\n",
      "8. cindylou@nova.edu - 25.00% Match\n",
      "9. c1phan@smith.edu - 12.50% Match\n",
      "10. john.doe@example.com - 0.00% Match\n",
      "11. emily.williams@example.com - 0.00% Match\n",
      "12. jane.smith@example.com - 0.00% Match\n",
      "13. alex.johnson@example.com - 0.00% Match\n",
      "Ranked data saved to ranked_candidates.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            return ''.join(page.extract_text() for page in pdf.pages)\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    skills_match = re.search(r\"SKILLS\\s*(.*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", skill).strip()\n",
    "        cleaned.extend(re.split(r\"[:,;/]+\", cleaned_skill))\n",
    "    return list(set(skill.strip().lower() for skill in cleaned if skill.strip()))\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (name, email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    name = re.search(r\"(?:name|full\\s*name|first\\s*name|last\\s*name)\\s*[:\\-]?\\s*(.*?)(?=\\n|email|$)\", text, re.IGNORECASE)\n",
    "    email = re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text)\n",
    "    phone = re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text)\n",
    "    \n",
    "    data = {\n",
    "        \"name\": name.group(1).strip() if name else \"Not available\",\n",
    "        \"email\": email.group(0) if email else \"Not available\",\n",
    "        \"phone\": phone.group(0) if phone else \"Not available\",\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    return data\n",
    "\n",
    "def save_to_csv(data, file_name=\"ranked_candidates.csv\"):\n",
    "    \"\"\"Saves ranked candidate data to CSV.\"\"\"\n",
    "    with open(file_name, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([ \"Phone\", \"Email\", \"Matched Skills\", \"Match Percentage\"])  # Header\n",
    "        for candidate in data:\n",
    "            writer.writerow([candidate[\"phone\"], candidate[\"email\"],\n",
    "                             ', '.join(candidate[\"skills\"]), f\"{candidate['match_percentage']:.2f}%\"])\n",
    "    print(f\"Ranked data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = candidate_set.intersection(required_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "def process_pdf_files_in_directory(directory_path, required_skills):\n",
    "    \"\"\"Processes all PDF files in the given directory.\"\"\"\n",
    "    candidates = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "            \n",
    "            # Load and parse the resume\n",
    "            text = load_pdf(file_path)\n",
    "            data = extract_info(text)\n",
    "\n",
    "             # Debugging extracted text\n",
    "            #print(\"Extracted Text:\")\n",
    "            #print(text)\n",
    "\n",
    "            # Evaluate candidate skills\n",
    "            matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "            # Store the candidate data with match percentage for ranking\n",
    "            candidate_data = data.copy()\n",
    "            candidate_data[\"match_percentage\"] = match_percentage\n",
    "            candidate_data[\"skills\"] = list(matched_skills)\n",
    "            candidates.append(candidate_data)\n",
    "\n",
    "    # Rank candidates based on match percentage\n",
    "    ranked_candidates = sorted(candidates, key=lambda x: x[\"match_percentage\"], reverse=True)\n",
    "\n",
    "    # Print the ranking in the desired format\n",
    "    print(\"\\nRanking Candidates:\")\n",
    "    for i, candidate in enumerate(ranked_candidates, start=1):\n",
    "        match_percentage = f\"{candidate['match_percentage']:.2f}%\"\n",
    "        email = candidate['email'] if candidate['email'] != \"Not available\" else \"Not available\"\n",
    "        print(f\"{i}. {email} - {match_percentage} Match\")\n",
    "\n",
    "    # Save the ranked candidates to CSV\n",
    "    save_to_csv(ranked_candidates)\n",
    "\n",
    "    return ranked_candidates\n",
    "\n",
    "# Example usage:\n",
    "directory_path = \"resumes\"  # Replace with the directory containing your PDF files\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process all PDF files in the directory\n",
    "ranked_candidates = process_pdf_files_in_directory(directory_path, required_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3adb57d1-0353-4ec7-b162-a2e530d80923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resume12.pdf...\n",
      "Matched Skills: {'java', 'django', 'python'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Candidate Data: {'email': 'ajaybkedare@gmail.com', 'phone': '9082168876', 'skills': ['hadoop mapreduce framework', 'shell', 'ojet', 'spring mvc', 'hibernate', 'jsf', 'sql server management studio', 'postgresql', 'django', 'mysql', 'c++', 'git', 'c', 'sed', 'ibatis', 'python', 'awk', 'programming & scripting languages', 'eclipse', 'tools & other technologies', 'pycharm', 'java', 'golang', 'jsp', 'puppet', 'angularjs', 'web technologies'], 'match_percentage': 37.5}\n",
      "Match Percentage: 37.50%\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            return ''.join(page.extract_text() for page in pdf.pages)\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    skills_match = re.search(r\"SKILLS\\s*(.*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", skill).strip()\n",
    "        cleaned.extend(re.split(r\"[:,;/]+\", cleaned_skill))\n",
    "    return list(set(skill.strip().lower() for skill in cleaned if skill.strip()))\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    return {key: (value.group(0) if value else \"Not available\") if key != \"skills\" else value for key, value in data.items()}\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow(data.keys())  # Write headers\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = candidate_set.intersection(required_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "def process_single_pdf(file_path, required_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "    # Output the matched skills and percentage\n",
    "    print(f\"Matched Skills: {matched_skills}\")\n",
    "    print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "    # Store the candidate data with match percentage for ranking\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"match_percentage\"] = match_percentage\n",
    "\n",
    "    # Save extracted data to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "    return candidate_data, match_percentage\n",
    "\n",
    "# Example usage for one resume:\n",
    "file_path = \"resume12.pdf\"  # Replace with the path to the resume PDF\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process a single PDF resume\n",
    "candidate_data, match_percentage = process_single_pdf(file_path, required_skills)\n",
    "\n",
    "# Output the result for the candidate\n",
    "print(f\"Candidate Data: {candidate_data}\")\n",
    "print(f\"Match Percentage: {match_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f3b639-d2dc-4ac6-9ddd-0f63b414eb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resumes\\computer-science-resume-example.pdf...\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\John Doe.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\My Resume.pdf...\n",
      "Matched Skills: {'python', 'java', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\Resume-Sample-2.pdf...\n",
      "Matched Skills: {'java', 'html'}\n",
      "Skill Match Percentage: 25.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\resume1.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\resume12.pdf...\n",
      "Matched Skills: {'java', 'django', 'python'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\resume2.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\resume3.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\sample-resumes_scs-3.pdf...\n",
      "Matched Skills: {'java', 'django', 'css', 'python'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\sample-resumes_scs-5.pdf...\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\sample-resumes_scs-6.pdf...\n",
      "Matched Skills: {'django', 'javascript', 'sql', 'java', 'python'}\n",
      "Skill Match Percentage: 62.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\science-cs-egr-resumes-5.pdf...\n",
      "Matched Skills: {'javascript'}\n",
      "Skill Match Percentage: 12.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\science-cs-egr-resumes-8.pdf...\n",
      "Matched Skills: {'java', 'django', 'python', 'html'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Data saved to resume_data1.csv\n",
      "Candidate Data: {'email': 'bellatrevino@email.com', 'phone': '(123) 456-7890', 'skills': ['with another member to share learnings', 'to schedule social media posts across instagram and twitter', 'obtained club approval', 'using web and tv campaigns', 'government', 'social media scheduler', 'illinois chicago to encourage exchanges among cs students', 'html', 'presented a need for a computer science club to student', '', 'which increased overall engagement rate by 23% for users', 'radio stations', 'computer science club', 'april 2017 - april 2020', 'css', 'networks with focus around use of twitter and instagram apis', 'git', 'of day of maximum engagement with social media posts', 'and news', 'led club members to spend 2 hours a week pair programming', 'and secured club advisor', 'co-founded the computer science club at the university of', 'co-founder', 'javascript', 'members to the club in first year', 'creator', 'built features using scikit-learn in python that learned the time', 'partnered with journalism majors to attract 35 active', 'surrounding new concepts and technical problems', 'rest apis', 'featured across 7 local newspapers', 'and it quickly grew to over 500 monthly active users', 'sql (postgresql', 'python  built responsive app using django and node that allowed users', 'released it for free for university of illinois chicago students', 'oracle)'], 'match_percentage': 37.5}\n",
      "Match Percentage: 37.50%\n",
      "Candidate Data: {'email': 'john.doe@example.com', 'phone': '+1 123 456 7890', 'skills': ['- react.js', '- sql', '- python', '- django', '- javascript'], 'match_percentage': 0.0}\n",
      "Match Percentage: 0.00%\n",
      "Candidate Data: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['kubernetes', 'jupyter', 'courses', 'structures', 'pytorch', '2020 - 08', '2024', 'azure', 'flask', 'intelligence', 'other skills', 'cloud computing', 'delhi', 'aws', '9.2', 'learning', 'c++', '10', 'frameworks & libraries', 'cloud platforms', 'tools & technologies', 'git', 'model optimization', 'work', 'debugging', 'python', 'data analysis', 'indian institute of technology', 'b.tech in computer science engineering', '08', 'tensorflow', 'programming languages', 'relevant courses', 'javascript', 'java', 'scikit-learn', 'cgpa', 'machine', 'artificial', 'rest apis', 'deep learning', 'docker', 'data', 'google cloud'], 'match_percentage': 37.5}\n",
      "Match Percentage: 37.50%\n",
      "Candidate Data: {'email': 'cindylou@nova.edu', 'phone': '954-555-1212', 'skills': ['skills', 'linux', 'self-motivated', 'windows (95', '\\uf0a7 software', '\\uf0a7 operating systems', 'html', 'microsoft office', 'mac os', 'vista)', '2000', 'mysql', 'strengths', 'creative thinker', 'c++', 'xp', '\\uf0a7 programming languages', 'excellent time management', 'detail-oriented', '98', 'matlab', 'perl', 'adobe photoshop and dreamweaver', '\\uf0a7 professional', 'java', '3ds max', 'php', 'scheme'], 'match_percentage': 25.0}\n",
      "Match Percentage: 25.00%\n",
      "Candidate Data: {'email': 'emily.williams@example.com', 'phone': '(111) 222-3333', 'skills': ['- machine learning', '- text analysis', '- neural networks', '- python', '- natural language processing'], 'match_percentage': 0.0}\n",
      "Match Percentage: 0.00%\n",
      "Candidate Data: {'email': 'ajaybkedare@gmail.com', 'phone': '9082168876', 'skills': ['hadoop mapreduce framework', 'shell', 'ojet', 'spring mvc', 'hibernate', 'jsf', 'sql server management studio', 'postgresql', 'django', 'mysql', 'c++', 'git', 'c', 'sed', 'ibatis', 'python', 'awk', 'programming & scripting languages', 'eclipse', 'tools & other technologies', 'pycharm', 'java', 'golang', 'jsp', 'puppet', 'angularjs', 'web technologies'], 'match_percentage': 37.5}\n",
      "Match Percentage: 37.50%\n",
      "Candidate Data: {'email': 'jane.smith@example.com', 'phone': '(987) 654-3210', 'skills': ['- user interface development', '- responsive design', '- css', '- html', '- javascript'], 'match_percentage': 0.0}\n",
      "Match Percentage: 0.00%\n",
      "Candidate Data: {'email': 'alex.johnson@example.com', 'phone': '(555) 123-4567', 'skills': ['- blockchain technology', '- decentralized applications', '- ethereum', '- smart contracts', '- solidity'], 'match_percentage': 0.0}\n",
      "Match Percentage: 0.00%\n",
      "Candidate Data: {'email': 'mtrix@andrew.cmu.edu', 'phone': '888-888-8881', 'skills': ['android', 'june 2015 - august 2015 | pittsburgh', 'data structures', 'django', 'html5', 'latex', 'led 3 person team developing mobile and wear apps for chorus', 'a web-', 'pa', 'sml', 'css', 'git', 'and maintain sensors.', 'python', 'patterns based crowdsourcing conversational assistant. has text to speech and', 'software design', 'spaces. target crowdsourcing effort to create 3-d models of buildings', 'speech to text capabilities. uses yelp search and yahoo apis.', 'java', 'c'], 'match_percentage': 50.0}\n",
      "Match Percentage: 50.00%\n",
      "Candidate Data: {'email': 'uxsi@gmail.com', 'phone': '(844)555-1905', 'skills': ['indesign', 'april 2014 cmu school of dramas playground illustrator', 'implemented a', 'cmu spring carnival head of marketing', 'president', 'branding brandux designer', 'jan 2011  nov 2013 cmu cmu', 'think aloud', 'involvement', 'storyboarding', 'b tests and measured results. oversaw', 'arduino', 'designer', 'html', 'orientation leader', 'brands. analyzed client sites and provided user research', 'fall 2014', 'aug 2011  aug 2013', 'design', 'photoshop', '2014 counterpoint a cappella', 'css', 'prototyping', 'contextual design', '5', 'recommendations to improve. devised and', 'heuristic evaluation', 'matlab', 'designed mobile sites and apps for major e-commerce', '2013  sketch', 'javascript', '2013', 'design of new products from conception to launch', 'persona design', 'aftereffects'], 'match_percentage': 37.5}\n",
      "Match Percentage: 37.50%\n",
      "Candidate Data: {'email': 'mackcrol@gmail.com', 'phone': '844-555-2626', 'skills': ['frameworks and tools', 'django', 'javascript', 'programming', 'java', 'sql', 'hadoop', 'maven', 'python', 'git', 'perl', 'scripting languages', 'c', 'matlab', 'dkpro for nlp'], 'match_percentage': 62.5}\n",
      "Match Percentage: 62.50%\n",
      "Candidate Data: {'email': 'c1phan@smith.edu', 'phone': '1063\\n612.685.3964', 'skills': ['adobe illustrator', 'ms office', 'latex', 'javascript', 'adobe photoshop', 'mathematica', 'co-curricular', 'labview', 'matlab'], 'match_percentage': 12.5}\n",
      "Match Percentage: 12.50%\n",
      "Candidate Data: {'email': 'msmith@smith.edu', 'phone': '413.555-1212', 'skills': ['django', 'java', 'technical', 'mathematica', 'python', 'languages', 'conversational spanish', 'html', 'and opengl'], 'match_percentage': 50.0}\n",
      "Match Percentage: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            return ''.join(page.extract_text() for page in pdf.pages)\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    skills_match = re.search(r\"SKILLS\\s*(.*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", skill).strip()\n",
    "        cleaned.extend(re.split(r\"[:,;/]+\", cleaned_skill))\n",
    "    return list(set(skill.strip().lower() for skill in cleaned if skill.strip()))\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    return {key: (value.group(0) if value else \"Not available\") if key != \"skills\" else value for key, value in data.items()}\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow(data.keys())  # Write headers\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = candidate_set.intersection(required_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "def process_single_pdf(file_path, required_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "    # Output the matched skills and percentage\n",
    "    print(f\"Matched Skills: {matched_skills}\")\n",
    "    print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "    # Store the candidate data with match percentage for ranking\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"match_percentage\"] = match_percentage\n",
    "\n",
    "    # Save extracted data to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "    return candidate_data, match_percentage\n",
    "\n",
    "def process_multiple_pdfs(pdf_folder, required_skills):\n",
    "    \"\"\"Processes multiple PDF resumes in a folder.\"\"\"\n",
    "    all_candidates_data = []\n",
    "\n",
    "    for file_name in os.listdir(pdf_folder):\n",
    "        if file_name.endswith('.pdf'):\n",
    "            file_path = os.path.join(pdf_folder, file_name)\n",
    "            candidate_data, match_percentage = process_single_pdf(file_path, required_skills)\n",
    "            all_candidates_data.append(candidate_data)\n",
    "\n",
    "    return all_candidates_data\n",
    "\n",
    "# Example usage:\n",
    "pdf_folder = \"resumes\"  # Replace with the folder containing the PDF resumes\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process all PDF resumes in the folder\n",
    "all_candidates_data = process_multiple_pdfs(pdf_folder, required_skills)\n",
    "\n",
    "# Output the results for all candidates\n",
    "for candidate_data in all_candidates_data:\n",
    "    print(f\"Candidate Data: {candidate_data}\")\n",
    "    print(f\"Match Percentage: {candidate_data['match_percentage']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c5c6188-c2bd-444b-b30d-ae709d2397be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resumes\\computer-science-resume-example.pdf...\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\John Doe.pdf...\n",
      "Matched Skills: {'sql', 'django', 'python', 'javascript'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\My Resume.pdf...\n",
      "Matched Skills: {'python', 'java', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\Resume-Sample-2.pdf...\n",
      "Matched Skills: {'java', 'html'}\n",
      "Skill Match Percentage: 25.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\resume1.pdf...\n",
      "Matched Skills: {'python'}\n",
      "Skill Match Percentage: 12.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\resume12.pdf...\n",
      "Matched Skills: {'java', 'django', 'python'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\resume2.pdf...\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\resume3.pdf...\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\sample-resumes_scs-3.pdf...\n",
      "Matched Skills: {'java', 'django', 'css', 'python'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\sample-resumes_scs-5.pdf...\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\sample-resumes_scs-6.pdf...\n",
      "Matched Skills: {'django', 'javascript', 'sql', 'java', 'python'}\n",
      "Skill Match Percentage: 62.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\science-cs-egr-resumes-5.pdf...\n",
      "Matched Skills: {'javascript'}\n",
      "Skill Match Percentage: 12.50%\n",
      "Data saved to resume_data1.csv\n",
      "Processing resumes\\science-cs-egr-resumes-8.pdf...\n",
      "Matched Skills: {'java', 'django', 'python', 'html'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Data saved to resume_data1.csv\n",
      "Candidate Data: {'email': 'bellatrevino@email.com', 'phone': '(123) 456-7890', 'skills': ['social media scheduler', 'javascript', 'creator', 'html', 'css', '', 'python  built responsive app using django and node that allowed users', 'to schedule social media posts across instagram and twitter', 'sql (postgresql', 'oracle)', 'built features using scikit-learn in python that learned the time', 'rest apis', 'of day of maximum engagement with social media posts', 'git', 'which increased overall engagement rate by 23% for users', 'released it for free for university of illinois chicago students', 'and it quickly grew to over 500 monthly active users', 'featured across 7 local newspapers', 'radio stations', 'and news', 'networks with focus around use of twitter and instagram apis', 'computer science club', 'co-founder', 'april 2017 - april 2020', 'presented a need for a computer science club to student', 'government', 'obtained club approval', 'and secured club advisor', 'co-founded the computer science club at the university of', 'illinois chicago to encourage exchanges among cs students', 'surrounding new concepts and technical problems', 'led club members to spend 2 hours a week pair programming', 'with another member to share learnings', 'partnered with journalism majors to attract 35 active', 'members to the club in first year', 'using web and tv campaigns'], 'match_percentage': 37.5, 'matched_skills': 'css, html, javascript'}\n",
      "Match Percentage: 37.50%\n",
      "Candidate Data: {'email': 'john.doe@example.com', 'phone': '+1 123 456 7890', 'skills': ['python', 'javascript', 'react.js', 'sql', 'django'], 'match_percentage': 50.0, 'matched_skills': 'sql, django, python, javascript'}\n",
      "Match Percentage: 50.00%\n",
      "Candidate Data: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech in computer science engineering', 'programming languages', 'python', 'java', 'c++', 'javascript', 'indian institute of technology', 'delhi', 'frameworks & libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020 - 08', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant courses', 'machine', 'cloud platforms', 'aws', 'google cloud', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools & technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep learning', 'rest apis', 'cloud computing', 'other skills', 'data analysis', 'model optimization', 'debugging', 'work'], 'match_percentage': 37.5, 'matched_skills': 'python, java, javascript'}\n",
      "Match Percentage: 37.50%\n",
      "Candidate Data: {'email': 'cindylou@nova.edu', 'phone': '954-555-1212', 'skills': ['strengths', '\\uf0a7 programming languages', 'perl', 'java', 'c++', 'html', 'php', 'mysql', 'scheme', 'matlab', '\\uf0a7 software', 'microsoft office', 'adobe photoshop and dreamweaver', '3ds max', '\\uf0a7 operating systems', 'windows (95', '98', '2000', 'xp', 'vista)', 'mac os', 'linux', '\\uf0a7 professional', 'self-motivated', 'creative thinker', 'detail-oriented', 'excellent time management', 'skills'], 'match_percentage': 25.0, 'matched_skills': 'java, html'}\n",
      "Match Percentage: 25.00%\n",
      "Candidate Data: {'email': 'emily.williams@example.com', 'phone': '(111) 222-3333', 'skills': ['natural language processing', 'machine learning', 'text analysis', 'python', 'neural networks'], 'match_percentage': 12.5, 'matched_skills': 'python'}\n",
      "Match Percentage: 12.50%\n",
      "Candidate Data: {'email': 'ajaybkedare@gmail.com', 'phone': '9082168876', 'skills': ['programming & scripting languages', 'c', 'c++', 'java', 'golang', 'python', 'shell', 'awk', 'sed', 'web technologies', 'angularjs', 'django', 'jsp', 'jsf', 'spring mvc', 'ojet', 'tools & other technologies', 'eclipse', 'pycharm', 'sql server management studio', 'git', 'puppet', 'ibatis', 'hibernate', 'mysql', 'postgresql', 'hadoop mapreduce framework'], 'match_percentage': 37.5, 'matched_skills': 'java, django, python'}\n",
      "Match Percentage: 37.50%\n",
      "Candidate Data: {'email': 'jane.smith@example.com', 'phone': '(987) 654-3210', 'skills': ['html', 'css', 'javascript', 'responsive design', 'user interface development'], 'match_percentage': 37.5, 'matched_skills': 'css, html, javascript'}\n",
      "Match Percentage: 37.50%\n",
      "Candidate Data: {'email': 'alex.johnson@example.com', 'phone': '(555) 123-4567', 'skills': ['solidity', 'ethereum', 'decentralized applications', 'smart contracts', 'blockchain technology'], 'match_percentage': 0.0, 'matched_skills': ''}\n",
      "Match Percentage: 0.00%\n",
      "Candidate Data: {'email': 'mtrix@andrew.cmu.edu', 'phone': '888-888-8881', 'skills': ['spaces. target crowdsourcing effort to create 3-d models of buildings', 'and maintain sensors.', 'java', 'python', 'c', 'sml', 'html5', 'june 2015 - august 2015 | pittsburgh', 'pa', 'css', 'django', 'android', 'latex', 'git', 'data structures', 'software design', 'led 3 person team developing mobile and wear apps for chorus', 'a web-', 'patterns based crowdsourcing conversational assistant. has text to speech and', 'speech to text capabilities. uses yelp search and yahoo apis.'], 'match_percentage': 50.0, 'matched_skills': 'java, django, css, python'}\n",
      "Match Percentage: 50.00%\n",
      "Candidate Data: {'email': 'uxsi@gmail.com', 'phone': '(844)555-1905', 'skills': ['branding brandux designer', 'fall 2014', 'designed mobile sites and apps for major e-commerce', 'brands. analyzed client sites and provided user research', 'contextual design', 'recommendations to improve. devised and', 'think aloud', 'implemented a', 'b tests and measured results. oversaw', 'persona design', 'design of new products from conception to launch', 'storyboarding', 'heuristic evaluation', 'involvement', 'design', 'cmu spring carnival head of marketing', '2013  sketch', 'photoshop', 'april 2014 cmu school of dramas playground illustrator', 'indesign', 'designer', '2013', '2014 counterpoint a cappella', 'aftereffects', 'president', 'jan 2011  nov 2013 cmu cmu', 'prototyping', 'html', 'css', 'orientation leader', 'aug 2011  aug 2013', 'javascript', 'matlab', 'arduino', '5'], 'match_percentage': 37.5, 'matched_skills': 'css, html, javascript'}\n",
      "Match Percentage: 37.50%\n",
      "Candidate Data: {'email': 'mackcrol@gmail.com', 'phone': '844-555-2626', 'skills': ['programming', 'scripting languages', 'java', 'python', 'c', 'sql', 'javascript', 'matlab', 'perl', 'frameworks and tools', 'hadoop', 'django', 'dkpro for nlp', 'maven', 'git'], 'match_percentage': 62.5, 'matched_skills': 'django, javascript, sql, java, python'}\n",
      "Match Percentage: 62.50%\n",
      "Candidate Data: {'email': 'c1phan@smith.edu', 'phone': '1063\\n612.685.3964', 'skills': ['mathematica', 'labview', 'latex', 'ms office', 'javascript', 'matlab', 'adobe illustrator', 'adobe photoshop', 'co-curricular'], 'match_percentage': 12.5, 'matched_skills': 'javascript'}\n",
      "Match Percentage: 12.50%\n",
      "Candidate Data: {'email': 'msmith@smith.edu', 'phone': '413.555-1212', 'skills': ['technical', 'python', 'java', 'django', 'mathematica', 'html', 'and opengl', 'languages', 'conversational spanish'], 'match_percentage': 50.0, 'matched_skills': 'java, django, python, html'}\n",
      "Match Percentage: 50.00%\n",
      "Sorted data saved to sorted_resume_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            return ''.join(page.extract_text() for page in pdf.pages)\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    skills_match = re.search(r\"SKILLS\\s*(.*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    return []\n",
    "\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    #print(f\"Cleaning skills: {raw_skills}\")\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"^\\s*-?\\s*\", \"\", skill)\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", cleaned_skill).strip()# text enclosed in parenthsis\n",
    "        cleaned.extend(re.split(r\"[:,;/]+\", cleaned_skill))\n",
    "    cleaned_skills = list(dict.fromkeys(skill.strip().lower() for skill in cleaned if skill.strip()))#original order maintained\n",
    "    #print(f\"Cleaned skills: {cleaned_skills}\")\n",
    "    return cleaned_skills\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    return {key: (value.group(0) if value else \"Not available\") if key != \"skills\" else value for key, value in data.items()}\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow(data.keys())  # Write headers\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = candidate_set.intersection(required_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "def process_single_pdf(file_path, required_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "    # Output the matched skills and percentage\n",
    "    print(f\"Matched Skills: {matched_skills}\")\n",
    "    print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "    # Store the candidate data with match percentage for ranking\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"match_percentage\"] = match_percentage\n",
    "    # Add matched_skills to the candidate data\n",
    "    candidate_data[\"matched_skills\"] = \", \".join(matched_skills)\n",
    "    # Save extracted data to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "    return candidate_data, match_percentage\n",
    "\n",
    "def process_multiple_pdfs(pdf_folder, required_skills):\n",
    "    \"\"\"Processes multiple PDF resumes in a folder.\"\"\"\n",
    "    all_candidates_data = []\n",
    "\n",
    "    for file_name in os.listdir(pdf_folder):\n",
    "        if file_name.endswith('.pdf'):\n",
    "            file_path = os.path.join(pdf_folder, file_name)\n",
    "            candidate_data, match_percentage = process_single_pdf(file_path, required_skills)\n",
    "            all_candidates_data.append(candidate_data)\n",
    "\n",
    "    return all_candidates_data\n",
    "\n",
    "def save_sorted_candidates(all_candidates_data, output_file=\"sorted_resume_data.csv\"):\n",
    "    \"\"\"Sort candidates by match percentage and save to CSV.\"\"\"\n",
    "    sorted_candidates = sorted(all_candidates_data, key=lambda x: x['match_percentage'], reverse=True)\n",
    "\n",
    "    # Save the sorted candidates to a new CSV file\n",
    "    with open(output_file, mode='w', newline='',encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if len(sorted_candidates) > 0:\n",
    "            headers=list(sorted_candidates[0].keys())\n",
    "            writer.writerow(headers)# Write headers\n",
    "            for candidate in sorted_candidates:\n",
    "                # Add matched skills as a new field in candidate data\n",
    "                matched_skills = \", \".join(candidate['skills'])  # Convert list of matched skills to a comma-separated string\n",
    "                writer.writerow(list(candidate.values()))  # Write candidate data\n",
    "\n",
    "    print(f\"Sorted data saved to {output_file}\")\n",
    "\n",
    "# Example usage:\n",
    "pdf_folder = \"resumes\"  # Replace with the folder containing the PDF resumes\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process all PDF resumes in the folder\n",
    "all_candidates_data = process_multiple_pdfs(pdf_folder, required_skills)\n",
    "for candidate_data in all_candidates_data:\n",
    "    print(f\"Candidate Data: {candidate_data}\")\n",
    "    print(f\"Match Percentage: {candidate_data['match_percentage']:.2f}%\")\n",
    "\n",
    "\n",
    "# Save the sorted candidates to a new CSV file\n",
    "save_sorted_candidates(all_candidates_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "010ddb2d-509d-48ef-bcae-12e5e004cfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing My Resume.pdf...\n",
      "Loading PDF: My Resume.pdf\n",
      "Extracted text from PDF: My Resume.pdf\n",
      "Ravi Gupta\n",
      "AI/ML Enthusiast | Computer Science Engineer\n",
      "Innovative and solution-driven computer science student passionate about artificial intelligence and\n",
      "machine learning. Adept at building and deploying AI-driven applications to solve real-world problems.\n",
      "ravigupta.2140@gmail.com 98342451271\n",
      "EDUCATION SKILLS\n",
      "B.Tech in Computer Science Engineering\n",
      "Programming Languages: Python, Java, C++, JavaScript\n",
      "Indian Institute of Technology, Delhi (IIT Delhi)\n",
      "Frameworks & Libraries: TensorFlow, PyTorch, Scikit-learn,\n",
      "08/2020 - 08/2024, CGPA: 9.2/10\n",
      "Flask\n",
      "Courses\n",
      "Relevant Courses: Machine\n",
      "Cloud Platforms: AWS, Google Cloud, Azure\n",
      "Learning, Artificial\n",
      "Intelligence, Data\n",
      "Tools & Technologies: Git, Docker, Kubernetes, Jupyter,\n",
      "Structures, Deep Learning,\n",
      "REST APIs\n",
      "Cloud Computing\n",
      "Other Skills: Data Analysis, Model Optimization,\n",
      "Debugging\n",
      "WORK EXPERIENCE\n",
      "Machine Learning Intern\n",
      "PERSONAL PROJECTS\n",
      "Workplace/Company\n",
      "05/2023 - 08/2023, 1. AI-Powered Personal Finance Assistant\n",
      "Google AI Research Lab, Bangalore\n",
      "Built an AI assistant using NLP for tracking and analyzing personal\n",
      "Achievements/Tasks expenses.Incorporated ML algorithms to forecast monthly\n",
      "Developed a neural network model for image recognition expenditure trends.Deployed on a Flask backend with a React-\n",
      "based user interface.\n",
      "tasks, improving accuracy by 15% compared to baseline.\n",
      "Implemented scalable pipelines for preprocessing large 2. Object Detection for Autonomous Vehicles\n",
      "datasets using TensorFlow and PyTorch. Developed a YOLO-based real-time object detection system.Trained\n",
      "on large datasets to identify road signs, vehicles, and\n",
      "Collaborated with a team of 10 researchers on optimizing\n",
      "pedestrians.Achieved 85% mAP (mean Average Precision) on\n",
      "hyperparameters using grid search and Bayesian benchmark datasets.\n",
      "optimization.\n",
      "3. Sentiment Analysis Tool for Social Media\n",
      "Software Development Intern Created a tool to analyze and visualize sentiment trends on Twitter\n",
      "using Python.Leveraged APIs to collect data and deployed models\n",
      "Workplace/Company using AWS Lambda for scalability.\n",
      "07/2022 - 08/2022,\n",
      "TCS Innovation Labs, Pune\n",
      "Achievements/Tasks ORGANIZATIONS\n",
      "Designed and implemented a chatbot for automated\n",
      "customer support using Natural Language Processing (NLP) Google Developer Student Club (GDSC) (2022 - Present)\n",
      "techniques. Organized hackathons and technical sessions on advanced ML topics.\n",
      "Integrated AWS services (Lambda, S3) for deployment and\n",
      "storage of models.\n",
      "CERTIFICATES\n",
      "Reduced response time for customer queries by 30% using\n",
      "an optimized inference engine.\n",
      "Deep Learning Specialization by Andrew Ng,\n",
      "Coursera AWS Certified Machine Learning  Specialty\n",
      "TensorFlow Developer Certification\n",
      "LANGUAGES\n",
      "English Hindi\n",
      "Full Professional Proficiency Full Professional Proficiency\n",
      "INTERESTS\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['B.Tech in Computer Science Engineering', 'Programming Languages: Python', ' Java', ' C++', ' JavaScript', 'Indian Institute of Technology', ' Delhi (IIT Delhi)', 'Frameworks & Libraries: TensorFlow', ' PyTorch', ' Scikit-learn', '08/2020 - 08/2024', ' CGPA: 9.2/10', 'Flask', 'Courses', 'Relevant Courses: Machine', 'Cloud Platforms: AWS', ' Google Cloud', ' Azure', 'Learning', ' Artificial', 'Intelligence', ' Data', 'Tools & Technologies: Git', ' Docker', ' Kubernetes', ' Jupyter', 'Structures', ' Deep Learning', 'REST APIs', 'Cloud Computing', 'Other Skills: Data Analysis', ' Model Optimization', 'Debugging', 'WORK ']\n",
      "Cleaning skills: ['B.Tech in Computer Science Engineering', 'Programming Languages: Python', 'Java', 'C++', 'JavaScript', 'Indian Institute of Technology', 'Delhi (IIT Delhi)', 'Frameworks & Libraries: TensorFlow', 'PyTorch', 'Scikit-learn', '08/2020 - 08/2024', 'CGPA: 9.2/10', 'Flask', 'Courses', 'Relevant Courses: Machine', 'Cloud Platforms: AWS', 'Google Cloud', 'Azure', 'Learning', 'Artificial', 'Intelligence', 'Data', 'Tools & Technologies: Git', 'Docker', 'Kubernetes', 'Jupyter', 'Structures', 'Deep Learning', 'REST APIs', 'Cloud Computing', 'Other Skills: Data Analysis', 'Model Optimization', 'Debugging', 'WORK']\n",
      "Cleaned skills: ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work']\n",
      "Extracted information: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'python', 'java', 'javascript'}\n",
      "Skill match percentage: 37.50%\n",
      "Matched Skills: {'python', 'java', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Saving data to resume_data1.csv...\n",
      "Data saved to resume_data1.csv\n",
      "Candidate Data: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work'], 'match_percentage': 37.5}\n",
      "Match Percentage: 37.50%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    print(f\"Loading PDF: {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "    print(f\"Extracted text from PDF: {file_path}\\n{text}\")\n",
    "    return text\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    print(\"Extracting skills...\")\n",
    "    skills_match = re.search(r\"SKILLS\\s*([\\s\\S]*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)#bullet operators unicode\n",
    "        print(f\"Raw skills extracted: {skills}\")\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    print(\"No skills section found.\")\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    print(f\"Cleaning skills: {raw_skills}\")\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"^\\s*-?\\s*\", \"\", skill)\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", cleaned_skill).strip()# text enclosed in parenthsis\n",
    "        \n",
    "        words = re.split(r\"[,\\s:/;]+\", cleaned_skill)\n",
    "        cleaned.extend(word.strip() for word in words if word.strip())\n",
    "    # Remove duplicates and normalize case\n",
    "    cleaned_skills = list(dict.fromkeys(word.lower() for word in cleaned))\n",
    "    print(f\"Cleaned skills: {cleaned_skills}\")\n",
    "    return cleaned_skills\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    print(\"Extracting key information (email, phone, etc.)...\")\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    result_data = {}\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key != \"skills\":\n",
    "            result_data[key] = value.group(0) if value else \"Not available\"\n",
    "        else:\n",
    "            result_data[key] = value\n",
    "    print(f\"Extracted information: {result_data}\")\n",
    "    return result_data\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    print(f\"Saving data to {file_name}...\")\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:  # Check if the file is empty to write headers\n",
    "            writer.writerow(data.keys())  # Write headers(\"name\", \"email\", \"phone\")\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    print(f\"Evaluating skills... Required skills: {required_skills}\")\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = candidate_set.intersection(required_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    print(f\"Matched skills: {matched_skills}\")\n",
    "    print(f\"Skill match percentage: {match_percentage:.2f}%\")\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "def process_single_pdf(file_path, required_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "    # Output the matched skills and percentage\n",
    "    print(f\"Matched Skills: {matched_skills}\")\n",
    "    print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "    # Store the candidate data with match percentage for ranking\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"match_percentage\"] = match_percentage\n",
    "\n",
    "    # Save extracted data to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "    return candidate_data, match_percentage\n",
    "\n",
    "# Example usage for one resume:\n",
    "#file_path = \"John Doe.pdf\"# Replace with the path to the resume PDF\n",
    "#file_path = \"computer-science-resume-example.pdf\"\n",
    "file_path = \"My Resume.pdf\"\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process a single PDF resume\n",
    "candidate_data, match_percentage = process_single_pdf(file_path, required_skills)\n",
    "\n",
    "# Output the result for the candidate\n",
    "print(f\"Candidate Data: {candidate_data}\")\n",
    "print(f\"Match Percentage: {match_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf2283fe-19c0-4e89-876c-3f7a76b936e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resumes in folder: resumes\n",
      "Processing resumes\\computer-science-resume-example.pdf...\n",
      "Loading PDF: resumes\\computer-science-resume-example.pdf\n",
      "Extracted text from PDF: resumes\\computer-science-resume-example.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['Social Media Scheduler', 'JavaScript (Angular)', 'Creator', 'HTML/ CSS', '', 'Python (Django) Built responsive app using Django and Node that allowed users', 'to schedule social media posts across Instagram and Twitter', 'SQL (PostgreSQL', ' Oracle)', '', 'Built features using scikit-learn in Python that learned the time', 'REST APIs', 'of day of maximum engagement with social media posts', 'Git', 'which increased overall engagement rate by 23% for users', '', 'Released it for free for University of Illinois Chicago students', 'and it quickly grew to over 500 monthly active users', '', 'Featured across 7 local newspapers', ' radio stations', ' and news', 'networks with focus around use of Twitter and Instagram APIs', 'Computer Science Club', 'Co-founder', 'April 2017 - April 2020', '', 'Presented a need for a computer science club to student', 'government', ' obtained club approval', ' and secured club advisor', '', 'Co-founded the computer science club at the University of', 'Illinois Chicago to encourage exchanges among CS students', 'surrounding new concepts and technical problems', '', 'Led club members to spend 2 hours a week pair programming', 'with another member to share learnings', '', 'Partnered with journalism majors to attract 35 active', 'members to the club in first year', ' using web and tv campaigns']\n",
      "Cleaning skills: ['Social Media Scheduler', 'JavaScript (Angular)', 'Creator', 'HTML/ CSS', '', 'Python (Django) Built responsive app using Django and Node that allowed users', 'to schedule social media posts across Instagram and Twitter', 'SQL (PostgreSQL', 'Oracle)', '', 'Built features using scikit-learn in Python that learned the time', 'REST APIs', 'of day of maximum engagement with social media posts', 'Git', 'which increased overall engagement rate by 23% for users', '', 'Released it for free for University of Illinois Chicago students', 'and it quickly grew to over 500 monthly active users', '', 'Featured across 7 local newspapers', 'radio stations', 'and news', 'networks with focus around use of Twitter and Instagram APIs', 'Computer Science Club', 'Co-founder', 'April 2017 - April 2020', '', 'Presented a need for a computer science club to student', 'government', 'obtained club approval', 'and secured club advisor', '', 'Co-founded the computer science club at the University of', 'Illinois Chicago to encourage exchanges among CS students', 'surrounding new concepts and technical problems', '', 'Led club members to spend 2 hours a week pair programming', 'with another member to share learnings', '', 'Partnered with journalism majors to attract 35 active', 'members to the club in first year', 'using web and tv campaigns']\n",
      "Cleaned skills: ['social', 'media', 'scheduler', 'javascript', 'creator', 'html', 'css', '', 'python', 'built', 'responsive', 'app', 'using', 'django', 'and', 'node', 'that', 'allowed', 'users', 'to', 'schedule', 'posts', 'across', 'instagram', 'twitter', 'sql', '(postgresql', 'oracle)', 'features', 'scikit-learn', 'in', 'learned', 'the', 'time', 'rest', 'apis', 'of', 'day', 'maximum', 'engagement', 'with', 'git', 'which', 'increased', 'overall', 'rate', 'by', '23%', 'for', 'released', 'it', 'free', 'university', 'illinois', 'chicago', 'students', 'quickly', 'grew', 'over', '500', 'monthly', 'active', 'featured', '7', 'local', 'newspapers', 'radio', 'stations', 'news', 'networks', 'focus', 'around', 'use', 'computer', 'science', 'club', 'co-founder', 'april', '2017', '-', '2020', 'presented', 'a', 'need', 'student', 'government', 'obtained', 'approval', 'secured', 'advisor', 'co-founded', 'at', 'encourage', 'exchanges', 'among', 'cs', 'surrounding', 'new', 'concepts', 'technical', 'problems', 'led', 'members', 'spend', '2', 'hours', 'week', 'pair', 'programming', 'another', 'member', 'share', 'learnings', 'partnered', 'journalism', 'majors', 'attract', '35', 'first', 'year', 'web', 'tv', 'campaigns']\n",
      "Extracted information: {'email': 'bellatrevino@email.com', 'phone': '(123) 456-7890', 'skills': ['social', 'media', 'scheduler', 'javascript', 'creator', 'html', 'css', '', 'python', 'built', 'responsive', 'app', 'using', 'django', 'and', 'node', 'that', 'allowed', 'users', 'to', 'schedule', 'posts', 'across', 'instagram', 'twitter', 'sql', '(postgresql', 'oracle)', 'features', 'scikit-learn', 'in', 'learned', 'the', 'time', 'rest', 'apis', 'of', 'day', 'maximum', 'engagement', 'with', 'git', 'which', 'increased', 'overall', 'rate', 'by', '23%', 'for', 'released', 'it', 'free', 'university', 'illinois', 'chicago', 'students', 'quickly', 'grew', 'over', '500', 'monthly', 'active', 'featured', '7', 'local', 'newspapers', 'radio', 'stations', 'news', 'networks', 'focus', 'around', 'use', 'computer', 'science', 'club', 'co-founder', 'april', '2017', '-', '2020', 'presented', 'a', 'need', 'student', 'government', 'obtained', 'approval', 'secured', 'advisor', 'co-founded', 'at', 'encourage', 'exchanges', 'among', 'cs', 'surrounding', 'new', 'concepts', 'technical', 'problems', 'led', 'members', 'spend', '2', 'hours', 'week', 'pair', 'programming', 'another', 'member', 'share', 'learnings', 'partnered', 'journalism', 'majors', 'attract', '35', 'first', 'year', 'web', 'tv', 'campaigns']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'django', 'javascript', 'sql', 'python', 'css', 'html'}\n",
      "Skill match percentage: 75.00%\n",
      "Matched Skills: {'django', 'javascript', 'sql', 'python', 'css', 'html'}\n",
      "Skill Match Percentage: 75.00%\n",
      "Processing resumes\\John Doe.pdf...\n",
      "Loading PDF: resumes\\John Doe.pdf\n",
      "Extracted text from PDF: resumes\\John Doe.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: [':', '- Python', '- JavaScript', '- React.js', '- SQL', '- Django']\n",
      "Cleaning skills: [':', '- Python', '- JavaScript', '- React.js', '- SQL', '- Django']\n",
      "Cleaned skills: ['python', 'javascript', 'react.js', 'sql', 'django']\n",
      "Extracted information: {'email': 'john.doe@example.com', 'phone': '+1 123 456 7890', 'skills': ['python', 'javascript', 'react.js', 'sql', 'django']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'sql', 'django', 'python', 'javascript'}\n",
      "Skill match percentage: 50.00%\n",
      "Matched Skills: {'sql', 'django', 'python', 'javascript'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Processing resumes\\My Resume.pdf...\n",
      "Loading PDF: resumes\\My Resume.pdf\n",
      "Extracted text from PDF: resumes\\My Resume.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['B.Tech in Computer Science Engineering', 'Programming Languages: Python', ' Java', ' C++', ' JavaScript', 'Indian Institute of Technology', ' Delhi (IIT Delhi)', 'Frameworks & Libraries: TensorFlow', ' PyTorch', ' Scikit-learn', '08/2020 - 08/2024', ' CGPA: 9.2/10', 'Flask', 'Courses', 'Relevant Courses: Machine', 'Cloud Platforms: AWS', ' Google Cloud', ' Azure', 'Learning', ' Artificial', 'Intelligence', ' Data', 'Tools & Technologies: Git', ' Docker', ' Kubernetes', ' Jupyter', 'Structures', ' Deep Learning', 'REST APIs', 'Cloud Computing', 'Other Skills: Data Analysis', ' Model Optimization', 'Debugging', 'WORK ']\n",
      "Cleaning skills: ['B.Tech in Computer Science Engineering', 'Programming Languages: Python', 'Java', 'C++', 'JavaScript', 'Indian Institute of Technology', 'Delhi (IIT Delhi)', 'Frameworks & Libraries: TensorFlow', 'PyTorch', 'Scikit-learn', '08/2020 - 08/2024', 'CGPA: 9.2/10', 'Flask', 'Courses', 'Relevant Courses: Machine', 'Cloud Platforms: AWS', 'Google Cloud', 'Azure', 'Learning', 'Artificial', 'Intelligence', 'Data', 'Tools & Technologies: Git', 'Docker', 'Kubernetes', 'Jupyter', 'Structures', 'Deep Learning', 'REST APIs', 'Cloud Computing', 'Other Skills: Data Analysis', 'Model Optimization', 'Debugging', 'WORK']\n",
      "Cleaned skills: ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work']\n",
      "Extracted information: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'python', 'java', 'javascript'}\n",
      "Skill match percentage: 37.50%\n",
      "Matched Skills: {'python', 'java', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Processing resumes\\Resume-Sample-2.pdf...\n",
      "Loading PDF: resumes\\Resume-Sample-2.pdf\n",
      "Extracted text from PDF: resumes\\Resume-Sample-2.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['/ STRENGTHS', '\\uf0a7 Programming languages: Perl', ' Java', ' C++', ' HTML', ' PHP', ' MySQL', ' Scheme', ' MatLab', '\\uf0a7 Software: Microsoft Office', ' Adobe Photoshop and Dreamweaver', ' 3ds Max', '\\uf0a7 Operating Systems: Windows (95', ' 98', ' 2000', ' XP', ' Vista)', ' Mac OS', ' Linux', '\\uf0a7 Professional: Self-motivated', ' creative thinker; detail-oriented; excellent time management', 'skills', '']\n",
      "Cleaning skills: ['/ STRENGTHS', '\\uf0a7 Programming languages: Perl', 'Java', 'C++', 'HTML', 'PHP', 'MySQL', 'Scheme', 'MatLab', '\\uf0a7 Software: Microsoft Office', 'Adobe Photoshop and Dreamweaver', '3ds Max', '\\uf0a7 Operating Systems: Windows (95', '98', '2000', 'XP', 'Vista)', 'Mac OS', 'Linux', '\\uf0a7 Professional: Self-motivated', 'creative thinker; detail-oriented; excellent time management', 'skills']\n",
      "Cleaned skills: ['strengths', '\\uf0a7', 'programming', 'languages', 'perl', 'java', 'c++', 'html', 'php', 'mysql', 'scheme', 'matlab', 'software', 'microsoft', 'office', 'adobe', 'photoshop', 'and', 'dreamweaver', '3ds', 'max', 'operating', 'systems', 'windows', '(95', '98', '2000', 'xp', 'vista)', 'mac', 'os', 'linux', 'professional', 'self-motivated', 'creative', 'thinker', 'detail-oriented', 'excellent', 'time', 'management', 'skills']\n",
      "Extracted information: {'email': 'cindylou@nova.edu', 'phone': '954-555-1212', 'skills': ['strengths', '\\uf0a7', 'programming', 'languages', 'perl', 'java', 'c++', 'html', 'php', 'mysql', 'scheme', 'matlab', 'software', 'microsoft', 'office', 'adobe', 'photoshop', 'and', 'dreamweaver', '3ds', 'max', 'operating', 'systems', 'windows', '(95', '98', '2000', 'xp', 'vista)', 'mac', 'os', 'linux', 'professional', 'self-motivated', 'creative', 'thinker', 'detail-oriented', 'excellent', 'time', 'management', 'skills']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'java', 'html'}\n",
      "Skill match percentage: 25.00%\n",
      "Matched Skills: {'java', 'html'}\n",
      "Skill Match Percentage: 25.00%\n",
      "Processing resumes\\resume1.pdf...\n",
      "Loading PDF: resumes\\resume1.pdf\n",
      "Extracted text from PDF: resumes\\resume1.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: [':', '- Natural Language Processing (NLP)', '- Machine Learning', '- Text Analysis', '- Python', '- Neural Networks']\n",
      "Cleaning skills: [':', '- Natural Language Processing (NLP)', '- Machine Learning', '- Text Analysis', '- Python', '- Neural Networks']\n",
      "Cleaned skills: ['natural', 'language', 'processing', 'machine', 'learning', 'text', 'analysis', 'python', 'neural', 'networks']\n",
      "Extracted information: {'email': 'emily.williams@example.com', 'phone': '(111) 222-3333', 'skills': ['natural', 'language', 'processing', 'machine', 'learning', 'text', 'analysis', 'python', 'neural', 'networks']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'python'}\n",
      "Skill match percentage: 12.50%\n",
      "Matched Skills: {'python'}\n",
      "Skill Match Percentage: 12.50%\n",
      "Processing resumes\\resume12.pdf...\n",
      "Loading PDF: resumes\\resume12.pdf\n",
      "Extracted text from PDF: resumes\\resume12.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['Programming & Scripting Languages: C', ' C++', ' Java', ' Golang', ' Python', ' Shell', ' AWK', ' SED', 'Web Technologies: AngularJS', ' Django', ' JSP', ' JSF', ' Spring MVC', ' OJET', 'Tools & Other Technologies: Eclipse', ' PyCharm', ' SQL Server Management Studio', ' Git', ' Puppet', ' iBatis', 'Hibernate', ' Mysql', ' Postgresql', ' Hadoop MapReduce framework']\n",
      "Cleaning skills: ['Programming & Scripting Languages: C', 'C++', 'Java', 'Golang', 'Python', 'Shell', 'AWK', 'SED', 'Web Technologies: AngularJS', 'Django', 'JSP', 'JSF', 'Spring MVC', 'OJET', 'Tools & Other Technologies: Eclipse', 'PyCharm', 'SQL Server Management Studio', 'Git', 'Puppet', 'iBatis', 'Hibernate', 'Mysql', 'Postgresql', 'Hadoop MapReduce framework']\n",
      "Cleaned skills: ['programming', '&', 'scripting', 'languages', 'c', 'c++', 'java', 'golang', 'python', 'shell', 'awk', 'sed', 'web', 'technologies', 'angularjs', 'django', 'jsp', 'jsf', 'spring', 'mvc', 'ojet', 'tools', 'other', 'eclipse', 'pycharm', 'sql', 'server', 'management', 'studio', 'git', 'puppet', 'ibatis', 'hibernate', 'mysql', 'postgresql', 'hadoop', 'mapreduce', 'framework']\n",
      "Extracted information: {'email': 'ajaybkedare@gmail.com', 'phone': '9082168876', 'skills': ['programming', '&', 'scripting', 'languages', 'c', 'c++', 'java', 'golang', 'python', 'shell', 'awk', 'sed', 'web', 'technologies', 'angularjs', 'django', 'jsp', 'jsf', 'spring', 'mvc', 'ojet', 'tools', 'other', 'eclipse', 'pycharm', 'sql', 'server', 'management', 'studio', 'git', 'puppet', 'ibatis', 'hibernate', 'mysql', 'postgresql', 'hadoop', 'mapreduce', 'framework']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'sql', 'django', 'python', 'java'}\n",
      "Skill match percentage: 50.00%\n",
      "Matched Skills: {'sql', 'django', 'python', 'java'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Processing resumes\\resume2.pdf...\n",
      "Loading PDF: resumes\\resume2.pdf\n",
      "Extracted text from PDF: resumes\\resume2.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: [':', '- HTML', '- CSS', '- JavaScript', '- Responsive Design', '- User Interface Development']\n",
      "Cleaning skills: [':', '- HTML', '- CSS', '- JavaScript', '- Responsive Design', '- User Interface Development']\n",
      "Cleaned skills: ['html', 'css', 'javascript', 'responsive', 'design', 'user', 'interface', 'development']\n",
      "Extracted information: {'email': 'jane.smith@example.com', 'phone': '(987) 654-3210', 'skills': ['html', 'css', 'javascript', 'responsive', 'design', 'user', 'interface', 'development']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'css', 'html', 'javascript'}\n",
      "Skill match percentage: 37.50%\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Processing resumes\\resume3.pdf...\n",
      "Loading PDF: resumes\\resume3.pdf\n",
      "Extracted text from PDF: resumes\\resume3.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: [':', '- Solidity', '- Ethereum', '- Decentralized Applications (dApps)', '- Smart Contracts', '- Blockchain Technology']\n",
      "Cleaning skills: [':', '- Solidity', '- Ethereum', '- Decentralized Applications (dApps)', '- Smart Contracts', '- Blockchain Technology']\n",
      "Cleaned skills: ['solidity', 'ethereum', 'decentralized', 'applications', 'smart', 'contracts', 'blockchain', 'technology']\n",
      "Extracted information: {'email': 'alex.johnson@example.com', 'phone': '(555) 123-4567', 'skills': ['solidity', 'ethereum', 'decentralized', 'applications', 'smart', 'contracts', 'blockchain', 'technology']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: set()\n",
      "Skill match percentage: 0.00%\n",
      "Matched Skills: set()\n",
      "Skill Match Percentage: 0.00%\n",
      "Processing resumes\\sample-resumes_scs-3.pdf...\n",
      "Loading PDF: resumes\\sample-resumes_scs-3.pdf\n",
      "Extracted text from PDF: resumes\\sample-resumes_scs-3.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['spaces. Target crowdsourcing effort to create 3-D models of buildings', 'and maintain sensors.', 'Java ', ' Python ', ' C ', ' SML ', ' HTML5 ', 'June 2015 - August 2015 | Pittsburgh', ' PA', 'CSS ', ' Django ', ' Android ', ' LATEX', ' Git', 'Data structures ', ' Software design ', ' Led 3 person team developing mobile and wear apps for Chorus', ' a web-', 'patterns based crowdsourcing conversational assistant. Has text to speech and', 'speech to text capabilities. Uses Yelp Search and Yahoo APIs.', '']\n",
      "Cleaning skills: ['spaces. Target crowdsourcing effort to create 3-D models of buildings', 'and maintain sensors.', 'Java', 'Python', 'C', 'SML', 'HTML5', 'June 2015 - August 2015 | Pittsburgh', 'PA', 'CSS', 'Django', 'Android', 'LATEX', 'Git', 'Data structures', 'Software design', 'Led 3 person team developing mobile and wear apps for Chorus', 'a web-', 'patterns based crowdsourcing conversational assistant. Has text to speech and', 'speech to text capabilities. Uses Yelp Search and Yahoo APIs.']\n",
      "Cleaned skills: ['spaces.', 'target', 'crowdsourcing', 'effort', 'to', 'create', '3-d', 'models', 'of', 'buildings', 'and', 'maintain', 'sensors.', 'java', 'python', 'c', 'sml', 'html5', 'june', '2015', '-', 'august', '|', 'pittsburgh', 'pa', 'css', 'django', 'android', 'latex', 'git', 'data', 'structures', 'software', 'design', 'led', '3', 'person', 'team', 'developing', 'mobile', 'wear', 'apps', 'for', 'chorus', 'a', 'web-', 'patterns', 'based', 'conversational', 'assistant.', 'has', 'text', 'speech', 'capabilities.', 'uses', 'yelp', 'search', 'yahoo', 'apis.']\n",
      "Extracted information: {'email': 'mtrix@andrew.cmu.edu', 'phone': '888-888-8881', 'skills': ['spaces.', 'target', 'crowdsourcing', 'effort', 'to', 'create', '3-d', 'models', 'of', 'buildings', 'and', 'maintain', 'sensors.', 'java', 'python', 'c', 'sml', 'html5', 'june', '2015', '-', 'august', '|', 'pittsburgh', 'pa', 'css', 'django', 'android', 'latex', 'git', 'data', 'structures', 'software', 'design', 'led', '3', 'person', 'team', 'developing', 'mobile', 'wear', 'apps', 'for', 'chorus', 'a', 'web-', 'patterns', 'based', 'conversational', 'assistant.', 'has', 'text', 'speech', 'capabilities.', 'uses', 'yelp', 'search', 'yahoo', 'apis.']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'java', 'django', 'css', 'python'}\n",
      "Skill match percentage: 50.00%\n",
      "Matched Skills: {'java', 'django', 'css', 'python'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Processing resumes\\sample-resumes_scs-5.pdf...\n",
      "Loading PDF: resumes\\sample-resumes_scs-5.pdf\n",
      "Extracted text from PDF: resumes\\sample-resumes_scs-5.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['Branding BrandUX Designer', ' Fall 2014', 'Designed mobile sites and apps for major e-commerce', 'brands. Analyzed client sites and provided User Research:', 'Contextual Design', 'recommendations to improve. Devised and', 'Think Aloud', 'implemented A/B tests and measured results. Oversaw', 'Persona Design', 'design of new products from conception to launch', 'Storyboarding', 'Heuristic Evaluation', 'Involvement', 'Design:', 'CMU Spring Carnival Head of Marketing', ' 2013  Sketch', 'Photoshop', 'April 2014 CMU School of Dramas Playground Illustrator', 'InDesign', 'Designer', ' 2013', ' 2014 Counterpoint A Cappella', 'AfterEffects', 'President', ' Jan 2011  Nov 2013 CMU CMU', 'Prototyping:', 'HTML/CSS', 'Orientation Leader', ' Aug 2011  Aug 2013', 'Javascript', 'MATLAB', 'Arduino', '5']\n",
      "Cleaning skills: ['Branding BrandUX Designer', 'Fall 2014', 'Designed mobile sites and apps for major e-commerce', 'brands. Analyzed client sites and provided User Research:', 'Contextual Design', 'recommendations to improve. Devised and', 'Think Aloud', 'implemented A/B tests and measured results. Oversaw', 'Persona Design', 'design of new products from conception to launch', 'Storyboarding', 'Heuristic Evaluation', 'Involvement', 'Design:', 'CMU Spring Carnival Head of Marketing', '2013  Sketch', 'Photoshop', 'April 2014 CMU School of Dramas Playground Illustrator', 'InDesign', 'Designer', '2013', '2014 Counterpoint A Cappella', 'AfterEffects', 'President', 'Jan 2011  Nov 2013 CMU CMU', 'Prototyping:', 'HTML/CSS', 'Orientation Leader', 'Aug 2011  Aug 2013', 'Javascript', 'MATLAB', 'Arduino', '5']\n",
      "Cleaned skills: ['branding', 'brandux', 'designer', 'fall', '2014', 'designed', 'mobile', 'sites', 'and', 'apps', 'for', 'major', 'e-commerce', 'brands.', 'analyzed', 'client', 'provided', 'user', 'research', 'contextual', 'design', 'recommendations', 'to', 'improve.', 'devised', 'think', 'aloud', 'implemented', 'a', 'b', 'tests', 'measured', 'results.', 'oversaw', 'persona', 'of', 'new', 'products', 'from', 'conception', 'launch', 'storyboarding', 'heuristic', 'evaluation', 'involvement', 'cmu', 'spring', 'carnival', 'head', 'marketing', '2013', '', 'sketch', 'photoshop', 'april', 'school', 'dramas', 'playground', 'illustrator', 'indesign', 'counterpoint', 'cappella', 'aftereffects', 'president', 'jan', '2011', 'nov', 'prototyping', 'html', 'css', 'orientation', 'leader', 'aug', 'javascript', 'matlab', 'arduino', '5']\n",
      "Extracted information: {'email': 'uxsi@gmail.com', 'phone': '(844)555-1905', 'skills': ['branding', 'brandux', 'designer', 'fall', '2014', 'designed', 'mobile', 'sites', 'and', 'apps', 'for', 'major', 'e-commerce', 'brands.', 'analyzed', 'client', 'provided', 'user', 'research', 'contextual', 'design', 'recommendations', 'to', 'improve.', 'devised', 'think', 'aloud', 'implemented', 'a', 'b', 'tests', 'measured', 'results.', 'oversaw', 'persona', 'of', 'new', 'products', 'from', 'conception', 'launch', 'storyboarding', 'heuristic', 'evaluation', 'involvement', 'cmu', 'spring', 'carnival', 'head', 'marketing', '2013', '', 'sketch', 'photoshop', 'april', 'school', 'dramas', 'playground', 'illustrator', 'indesign', 'counterpoint', 'cappella', 'aftereffects', 'president', 'jan', '2011', 'nov', 'prototyping', 'html', 'css', 'orientation', 'leader', 'aug', 'javascript', 'matlab', 'arduino', '5']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'css', 'html', 'javascript'}\n",
      "Skill match percentage: 37.50%\n",
      "Matched Skills: {'css', 'html', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Processing resumes\\sample-resumes_scs-6.pdf...\n",
      "Loading PDF: resumes\\sample-resumes_scs-6.pdf\n",
      "Extracted text from PDF: resumes\\sample-resumes_scs-6.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['Programming/Scripting Languages: (Proficient) Java; (Familiar) Python', ' C', ' SQL', ' Javascript', ' MATLAB', ' Perl', 'Frameworks and tools: Hadoop', ' Django', ' DKPro for NLP', ' Maven', ' Git', '']\n",
      "Cleaning skills: ['Programming/Scripting Languages: (Proficient) Java; (Familiar) Python', 'C', 'SQL', 'Javascript', 'MATLAB', 'Perl', 'Frameworks and tools: Hadoop', 'Django', 'DKPro for NLP', 'Maven', 'Git']\n",
      "Cleaned skills: ['programming', 'scripting', 'languages', 'java', 'python', 'c', 'sql', 'javascript', 'matlab', 'perl', 'frameworks', 'and', 'tools', 'hadoop', 'django', 'dkpro', 'for', 'nlp', 'maven', 'git']\n",
      "Extracted information: {'email': 'mackcrol@gmail.com', 'phone': '844-555-2626', 'skills': ['programming', 'scripting', 'languages', 'java', 'python', 'c', 'sql', 'javascript', 'matlab', 'perl', 'frameworks', 'and', 'tools', 'hadoop', 'django', 'dkpro', 'for', 'nlp', 'maven', 'git']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'django', 'javascript', 'sql', 'java', 'python'}\n",
      "Skill match percentage: 62.50%\n",
      "Matched Skills: {'django', 'javascript', 'sql', 'java', 'python'}\n",
      "Skill Match Percentage: 62.50%\n",
      "Processing resumes\\science-cs-egr-resumes-5.pdf...\n",
      "Loading PDF: resumes\\science-cs-egr-resumes-5.pdf\n",
      "Extracted text from PDF: resumes\\science-cs-egr-resumes-5.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['Mathematica', ' LabVIEW', ' LaTeX', ' MS Office', ' JavaScript', ' MATLAB', ' ', ' Adobe Illustrator', ' Adobe Photoshop', 'CO-CURRICULAR ']\n",
      "Cleaning skills: ['Mathematica', 'LabVIEW', 'LaTeX', 'MS Office', 'JavaScript', 'MATLAB', 'Adobe Illustrator', 'Adobe Photoshop', 'CO-CURRICULAR']\n",
      "Cleaned skills: ['mathematica', 'labview', 'latex', 'ms', 'office', 'javascript', 'matlab', 'adobe', 'illustrator', 'photoshop', 'co-curricular']\n",
      "Extracted information: {'email': 'c1phan@smith.edu', 'phone': '1063\\n612.685.3964', 'skills': ['mathematica', 'labview', 'latex', 'ms', 'office', 'javascript', 'matlab', 'adobe', 'illustrator', 'photoshop', 'co-curricular']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'javascript'}\n",
      "Skill match percentage: 12.50%\n",
      "Matched Skills: {'javascript'}\n",
      "Skill Match Percentage: 12.50%\n",
      "Processing resumes\\science-cs-egr-resumes-8.pdf...\n",
      "Loading PDF: resumes\\science-cs-egr-resumes-8.pdf\n",
      "Extracted text from PDF: resumes\\science-cs-egr-resumes-8.pdf\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['Technical: Python', ' Java', ' Django', ' Mathematica', ' HTML', ' and OpenGL', 'Languages: Conversational Spanish', '']\n",
      "Cleaning skills: ['Technical: Python', 'Java', 'Django', 'Mathematica', 'HTML', 'and OpenGL', 'Languages: Conversational Spanish']\n",
      "Cleaned skills: ['technical', 'python', 'java', 'django', 'mathematica', 'html', 'and', 'opengl', 'languages', 'conversational', 'spanish']\n",
      "Extracted information: {'email': 'msmith@smith.edu', 'phone': '413.555-1212', 'skills': ['technical', 'python', 'java', 'django', 'mathematica', 'html', 'and', 'opengl', 'languages', 'conversational', 'spanish']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'java', 'django', 'python', 'html'}\n",
      "Skill match percentage: 50.00%\n",
      "Matched Skills: {'java', 'django', 'python', 'html'}\n",
      "Skill Match Percentage: 50.00%\n",
      "Saving ranked candidates to ranked_resumes.csv...\n",
      "Ranked resumes saved to ranked_resumes.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    print(f\"Loading PDF: {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "    print(f\"Extracted text from PDF: {file_path}\")\n",
    "    return text\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    print(\"Extracting skills...\")\n",
    "    skills_match = re.search(r\"SKILLS\\s*(.*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)  # Bullet operators unicode\n",
    "        print(f\"Raw skills extracted: {skills}\")\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    print(\"No skills section found.\")\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    print(f\"Cleaning skills: {raw_skills}\")\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"^\\s*-?\\s*\", \"\", skill)\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", cleaned_skill).strip()# text enclosed in parenthsis\n",
    "        \n",
    "        words = re.split(r\"[,\\s:/;]+\", cleaned_skill)\n",
    "        cleaned.extend(word.strip() for word in words if word.strip())\n",
    "    # Remove duplicates and normalize case\n",
    "    cleaned_skills = list(dict.fromkeys(word.lower() for word in cleaned))\n",
    "    print(f\"Cleaned skills: {cleaned_skills}\")\n",
    "    return cleaned_skills\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    print(\"Extracting key information (email, phone, etc.)...\")\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    result_data = {}\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key != \"skills\":\n",
    "            result_data[key] = value.group(0) if value else \"Not available\"\n",
    "        else:\n",
    "            result_data[key] = value\n",
    "    print(f\"Extracted information: {result_data}\")\n",
    "    return result_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_to_csv(data, file_name):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    print(f\"Saving data to {file_name}...\")\n",
    "    with open(file_name, mode='a', newline='', encoding='utf-8' ,errors='ignore') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:  # Check if the file is empty to write headers\n",
    "            writer.writerow(data.keys())  # Write headers(\"name\", \"email\", \"phone\")\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    print(f\"Evaluating skills... Required skills: {required_skills}\")\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = candidate_set.intersection(required_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    print(f\"Matched skills: {matched_skills}\")\n",
    "    print(f\"Skill match percentage: {match_percentage:.2f}%\")\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "def process_single_pdf(file_path, required_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "    # Output the matched skills and percentage\n",
    "    print(f\"Matched Skills: {matched_skills}\")\n",
    "    print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "    # Store the candidate data with match percentage for ranking\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"matched_skills\"] = \", \".join(matched_skills)\n",
    "    candidate_data[\"match_percentage\"] = match_percentage\n",
    "\n",
    "    return candidate_data, match_percentage\n",
    "\n",
    "def process_multiple_resumes(folder_path, required_skills, output_csv=\"ranked_resumes.csv\"):\n",
    "    \"\"\"Process all resumes in a folder, rank them by match percentage, and save to CSV.\"\"\"\n",
    "    print(f\"Processing resumes in folder: {folder_path}\")\n",
    "    all_candidates = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            candidate_data, match_percentage = process_single_pdf(file_path, required_skills)\n",
    "            candidate_data[\"filename\"] = filename\n",
    "            all_candidates.append(candidate_data)\n",
    "    \n",
    "    # Sort candidates by match percentage\n",
    "    ranked_candidates = sorted(all_candidates, key=lambda x: x[\"match_percentage\"], reverse=True)\n",
    "\n",
    "    # Save the ranked candidates to the new CSV\n",
    "    print(f\"Saving ranked candidates to {output_csv}...\")\n",
    "    with open(output_csv, mode='w', newline='',encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"email\", \"phone\", \"match_percentage\", \"matched_skills\", \"skills\",\"filename\"])  # CSV header\n",
    "        for candidate in ranked_candidates:\n",
    "            writer.writerow([\n",
    "                candidate[\"email\"],\n",
    "                candidate[\"phone\"],\n",
    "                candidate[\"match_percentage\"],\n",
    "                candidate[\"matched_skills\"],\n",
    "                \", \".join(candidate[\"skills\"]), \n",
    "                candidate[\"filename\"]\n",
    "            ])\n",
    "    print(f\"Ranked resumes saved to {output_csv}\")\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"resumes\"  # Replace with the path to the folder containing the resumes\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process multiple resumes and save the ranked list to CSV\n",
    "process_multiple_resumes(folder_path, required_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e6f9cc8-ad25-4407-90fc-2cb8385fa751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample-resumes_scs-6.pdf...\n",
      "Loading PDF: sample-resumes_scs-6.pdf\n",
      "Extracted text from PDF: sample-resumes_scs-6.pdf\n",
      "MACK CROLANGUAGE\n",
      "844-555-2626 | mackcrol@gmail.com\n",
      "EDUCATION\n",
      "Carnegie Mellon University, Pittsburgh, PA\n",
      "Master of Science, Computer Science, December 2015\n",
      "Selected Coursework: Introduction to Machine Learning (10-601, Fall 2014), Distributed Systems (15-440/640, Fall 2014),\n",
      "Algorithm Design and Analysis (15-451/651, Fall 2014), Web Apps Development (15-637, Spring 2015), Machine Learning\n",
      "with Large Datasets (10-605, Spring 2015), Graduate Artificial Intelligence (15-780, Spring 2015)\n",
      "Birla Institute of Technology and Science, Pilani, India\n",
      "Bachelor of Engineering (Hons.), Computer Science (Minor: M.Sc. Economics), July 2014\n",
      "SKILLS\n",
      "Programming/Scripting Languages: (Proficient) Java; (Familiar) Python, C, SQL, Javascript, MATLAB, Perl\n",
      "Frameworks and tools: Hadoop, Django, DKPro for NLP, Maven, Git\n",
      "EXPERIENCE\n",
      "Software Engineering Intern\n",
      "Yahoo! Inc., Sunnyvale, CA, May - August, 2015\n",
      " Interned with the user data team, which is part of cloud services at Yahoo!\n",
      "Research Intern\n",
      "Ubiquitous Knowledge Processing Lab, TU Darmstadt, Germany, January - June, 2014\n",
      " Developed an application (in Java) using the DKPro library to automatically solve multiple choice reading comprehension\n",
      "nd\n",
      "questions. Using text similarity and textual entailment measures, it obtained the 2 best score in the CLEF Entrance Exams\n",
      "competition.\n",
      "Research Student\n",
      "Computer Engineering and Networks Laboratory, ETH Zurich, Switzerland, July - December, 2013\n",
      " Developed an application (in Python) to use a tree-based learning algorithm to model the deadline hit and miss patterns of\n",
      "periodic real-time tasks. The algorithm used formal verification techniques to generate a regular language-based guarantee to\n",
      "predict future deadline hits and misses.\n",
      "Developer (Google Summer of Code)\n",
      "Student Developer for National Resource for Network Biology (NRNB), Summer 2012\n",
      " Built an app (in Java) for Cytoscape, an open-source software for complex network visualization. The app helped users to\n",
      "visually analyze and modify molecular interaction networks.\n",
      "PROJECTS\n",
      "MapReduce Engine\n",
      "Carnegie Mellon University, Fall 2014\n",
      " Implemented a Hadoop-like MapReduce facility, with master and worker nodes for map-reduce operations over large datasets,\n",
      "with a distributed file system, and fault tolerance to address datanode failures.\n",
      "Object Recognition Using CIFAR-10 Dataset\n",
      "Carnegie Mellon University, Fall 2014\n",
      " As part of an in-class Kaggle competition, several approaches were tried to train a model using 4000 images for the\n",
      "CIFAR-10 dataset. With GIST descriptors and a Kernelized (RBF) SVM, a test accuracy of 61% was obtained on a dataset\n",
      "consisting of 15000 images.\n",
      "Intelligent Indoor Emergency Response System\n",
      "Carnegie Mellon University, Spring 2015\n",
      " Developed a priority-based auctioning algorithm for task allocation in a multi-agent environment. Using a modified A*\n",
      "algorithm, tasks were prioritized based on proximity to the location of the fire resulting in an efficient evacuation.\n",
      "6\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['Programming/Scripting Languages: (Proficient) Java; (Familiar) Python', ' C', ' SQL', ' Javascript', ' MATLAB', ' Perl', 'Frameworks and tools: Hadoop', ' Django', ' DKPro for NLP', ' Maven', ' Git', '']\n",
      "Cleaning skills: ['Programming/Scripting Languages: (Proficient) Java; (Familiar) Python', 'C', 'SQL', 'Javascript', 'MATLAB', 'Perl', 'Frameworks and tools: Hadoop', 'Django', 'DKPro for NLP', 'Maven', 'Git']\n",
      "Cleaned skills: ['programming', 'scripting', 'languages', 'java', 'python', 'c', 'sql', 'javascript', 'matlab', 'perl', 'frameworks', 'and', 'tools', 'hadoop', 'django', 'dkpro', 'for', 'nlp', 'maven', 'git']\n",
      "Extracted information: {'email': 'mackcrol@gmail.com', 'phone': '844-555-2626', 'skills': ['programming', 'scripting', 'languages', 'java', 'python', 'c', 'sql', 'javascript', 'matlab', 'perl', 'frameworks', 'and', 'tools', 'hadoop', 'django', 'dkpro', 'for', 'nlp', 'maven', 'git']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched required skills: {'django', 'javascript', 'sql', 'java', 'python'}\n",
      "Matched good-to-have skills: {'perl'}\n",
      "Skill match percentage: 62.50%\n",
      "Bonus percentage for good-to-have skills: 6.00%\n",
      "Total match percentage: 68.50%\n",
      "Matched Required Skills: {'django', 'javascript', 'sql', 'java', 'python'}\n",
      "Matched Good-to-Have Skills: {'perl'}\n",
      "Total Match Percentage: 68.50%\n",
      "Saving data to resume_data1.csv...\n",
      "Data saved to resume_data1.csv\n",
      "Candidate Data: {'email': 'mackcrol@gmail.com', 'phone': '844-555-2626', 'skills': ['programming', 'scripting', 'languages', 'java', 'python', 'c', 'sql', 'javascript', 'matlab', 'perl', 'frameworks', 'and', 'tools', 'hadoop', 'django', 'dkpro', 'for', 'nlp', 'maven', 'git'], 'total_match_percentage': 68.5}\n",
      "Total Match Percentage: 68.50%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    print(f\"Loading PDF: {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "    print(f\"Extracted text from PDF: {file_path}\\n{text}\")\n",
    "    return text\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    print(\"Extracting skills...\")\n",
    "    skills_match = re.search(r\"SKILLS\\s*([\\s\\S]*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)#bullet operators unicode\n",
    "        print(f\"Raw skills extracted: {skills}\")\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    print(\"No skills section found.\")\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    print(f\"Cleaning skills: {raw_skills}\")\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"^\\s*-?\\s*\", \"\", skill)\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", cleaned_skill).strip()# text enclosed in parenthsis\n",
    "        \n",
    "        words = re.split(r\"[,\\s:/;]+\", cleaned_skill)\n",
    "        cleaned.extend(word.strip() for word in words if word.strip())\n",
    "    # Remove duplicates and normalize case\n",
    "    cleaned_skills = list(dict.fromkeys(word.lower() for word in cleaned))\n",
    "    print(f\"Cleaned skills: {cleaned_skills}\")\n",
    "    return cleaned_skills\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    print(\"Extracting key information (email, phone, etc.)...\")\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    result_data = {}\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key != \"skills\":\n",
    "            result_data[key] = value.group(0) if value else \"Not available\"\n",
    "        else:\n",
    "            result_data[key] = value\n",
    "    print(f\"Extracted information: {result_data}\")\n",
    "    return result_data\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    print(f\"Saving data to {file_name}...\")\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:  # Check if the file is empty to write headers\n",
    "            writer.writerow(data.keys())  # Write headers(\"name\", \"email\", \"phone\")\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills, good_to_have_skills):\n",
    "    \"\"\"Matches candidate's skills with required and good-to-have skills.\"\"\"\n",
    "    print(f\"Evaluating skills... Required skills: {required_skills}\")\n",
    "    \n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    good_to_have_set = set(map(str.lower, good_to_have_skills.split(\", \")))\n",
    "\n",
    "    matched_required_skills = candidate_set.intersection(required_set)\n",
    "    matched_good_to_have_skills = candidate_set.intersection(good_to_have_set)\n",
    "\n",
    "    # Calculate match percentages\n",
    "    match_percentage = (len(matched_required_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    bonus_percentage = (len(matched_good_to_have_skills) / len(good_to_have_set)) * 30 if good_to_have_set else 0\n",
    "    \n",
    "    total_match_percentage = match_percentage + bonus_percentage\n",
    "    \n",
    "    print(f\"Matched required skills: {matched_required_skills}\")\n",
    "    print(f\"Matched good-to-have skills: {matched_good_to_have_skills}\")\n",
    "    print(f\"Skill match percentage: {match_percentage:.2f}%\")\n",
    "    print(f\"Bonus percentage for good-to-have skills: {bonus_percentage:.2f}%\")\n",
    "    print(f\"Total match percentage: {total_match_percentage:.2f}%\")\n",
    "    \n",
    "    return matched_required_skills, matched_good_to_have_skills, total_match_percentage\n",
    "\n",
    "\n",
    "def process_single_pdf(file_path, required_skills, good_to_have_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_required_skills, matched_good_to_have_skills, total_match_percentage = evaluate_skills(data[\"skills\"], required_skills, good_to_have_skills)\n",
    "\n",
    "    # Output the matched skills and percentage\n",
    "    print(f\"Matched Required Skills: {matched_required_skills}\")\n",
    "    print(f\"Matched Good-to-Have Skills: {matched_good_to_have_skills}\")\n",
    "    print(f\"Total Match Percentage: {total_match_percentage:.2f}%\")\n",
    "\n",
    "    # Store the candidate data with match percentage for ranking\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"total_match_percentage\"] = total_match_percentage\n",
    "\n",
    "    # Save extracted data to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "    return candidate_data, total_match_percentage\n",
    "\n",
    "# Example usage for one resume:\n",
    "file_path = \"sample-resumes_scs-6.pdf\"\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "good_to_have_skills = \"Node.js, Docker, Perl, AWS, TypeScript,Git\"  # Example good-to-have skills\n",
    "\n",
    "# Process a single PDF resume\n",
    "candidate_data, total_match_percentage = process_single_pdf(file_path, required_skills, good_to_have_skills)\n",
    "\n",
    "# Output the result for the candidate\n",
    "print(f\"Candidate Data: {candidate_data}\")\n",
    "print(f\"Total Match Percentage: {total_match_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4709c4a-fc6e-418a-9daf-5e1263aa9520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Ranked Candidates:**\n",
      "{'Filename': 'sample-resumes_scs-6.pdf', 'Email': 'mackcrol@gmail.com', 'Phone': '844-555-2626', 'Matched Required Skills': 'sql, python, java', 'Matched Good-to-Have Skills': 'git, javascript', 'Match Percentage': '88.00%'}\n",
      "{'Filename': 'resume12.pdf', 'Email': 'ajaybkedare@gmail.com', 'Phone': '9082168876', 'Matched Required Skills': 'sql, python, java', 'Matched Good-to-Have Skills': 'git', 'Match Percentage': '84.00%'}\n",
      "CSV file saved as ranked_resumes.csv. You can download it from the filesystem.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import io\n",
    "import hashlib\n",
    "\n",
    "# Functions from your previous code\n",
    "def load_pdf(file):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    # Use BytesIO to read the uploaded file as a file object\n",
    "    with io.BytesIO(file.read()) as byte_file:\n",
    "        with pdfplumber.open(byte_file) as pdf:\n",
    "            text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "    return text\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    skills_match = re.search(r\"SKILLS\\s*(.*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)  # Bullet operators unicode\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"^\\s*-?\\s*\", \"\", skill)\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", cleaned_skill).strip()  # Text enclosed in parentheses\n",
    "        words = re.split(r\"[,\\s:/;]+\", cleaned_skill)\n",
    "        cleaned.extend(word.strip() for word in words if word.strip())\n",
    "    # Remove duplicates and normalize case\n",
    "    return list(dict.fromkeys(word.lower() for word in cleaned))\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    result_data = {}\n",
    "    for key, value in data.items():\n",
    "        if key != \"skills\":\n",
    "            result_data[key] = value.group(0) if value else \"Not available\"\n",
    "        else:\n",
    "            result_data[key] = value\n",
    "    return result_data\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills, good_to_have_skills):\n",
    "    \"\"\"Matches candidate's skills with required and good-to-have skills.\"\"\"\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    good_to_have_set = set(map(str.lower, good_to_have_skills.split(\", \")))\n",
    "\n",
    "    matched_required_skills = candidate_set.intersection(required_set)\n",
    "    matched_good_to_have_skills = candidate_set.intersection(good_to_have_set)\n",
    "\n",
    "    # Calculate match percentages\n",
    "    match_percentage = (len(matched_required_skills) / len(required_set)) * 80 if required_set else 0\n",
    "    bonus_percentage = (len(matched_good_to_have_skills) / len(good_to_have_set)) * 20 if good_to_have_set else 0  # Increase weightage for good-to-have\n",
    "\n",
    "    total_match_percentage = match_percentage + bonus_percentage\n",
    "\n",
    "    return matched_required_skills, matched_good_to_have_skills, total_match_percentage\n",
    "\n",
    "def process_single_pdf(file, required_skills, good_to_have_skills, processed_hashes):\n",
    "    \"\"\"Processes a single PDF resume file and prevents duplicate processing.\"\"\"\n",
    "    file_hash = generate_file_hash(file)\n",
    "    \n",
    "    # Skip file if it's already processed\n",
    "    if file_hash in processed_hashes:\n",
    "        return None\n",
    "    \n",
    "    text = load_pdf(file)\n",
    "    data = extract_info(text)\n",
    "    matched_required_skills, matched_good_to_have_skills, total_match_percentage = evaluate_skills(data[\"skills\"], required_skills, good_to_have_skills)\n",
    "\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"matched_skills\"] = \", \".join(matched_required_skills)\n",
    "    candidate_data[\"matched_good_to_have_skills\"] = \", \".join(matched_good_to_have_skills)  # Add matched good-to-have skills\n",
    "    candidate_data[\"match_percentage\"] = total_match_percentage\n",
    "    processed_hashes.add(file_hash)  # Add file hash to processed set\n",
    "\n",
    "    return candidate_data\n",
    "\n",
    "def generate_file_hash(file):\n",
    "    \"\"\"Generates a unique hash for the uploaded file based on its content.\"\"\"\n",
    "    file_content = file.read()  # Read the file content\n",
    "    file.seek(0)  # Reset file pointer after reading\n",
    "    return hashlib.md5(file_content).hexdigest()  # Generate MD5 hash of the content\n",
    "\n",
    "def save_to_csv(data, file_name):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    with open(file_name, mode='a', newline='', encoding='utf-8', errors='ignore') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:  # Check if the file is empty to write headers\n",
    "            writer.writerow(data.keys())  # Write headers\n",
    "        writer.writerow(data.values())  # Write values\n",
    "\n",
    "# Main function to process PDFs\n",
    "def process_resumes(uploaded_files, required_skills, good_to_have_skills):\n",
    "    processed_hashes = set()\n",
    "    \n",
    "    all_candidates = []\n",
    "    for uploaded_file in uploaded_files:\n",
    "        candidate_data = process_single_pdf(uploaded_file, required_skills, good_to_have_skills, processed_hashes)\n",
    "        \n",
    "        # Skip processing if the file was already processed\n",
    "        if candidate_data is None:\n",
    "            continue\n",
    "        \n",
    "        candidate_data[\"filename\"] = uploaded_file.name\n",
    "        all_candidates.append(candidate_data)\n",
    "\n",
    "    # Rank candidates based on match percentage\n",
    "    ranked_candidates = sorted(all_candidates, key=lambda x: x[\"match_percentage\"], reverse=True)\n",
    "    \n",
    "    # Display ranked candidates\n",
    "    if ranked_candidates:\n",
    "        print(\"**Ranked Candidates:**\")\n",
    "        table_data = []\n",
    "        for candidate in ranked_candidates:\n",
    "            table_data.append({\n",
    "                \"Filename\": candidate[\"filename\"],\n",
    "                \"Email\": candidate[\"email\"],\n",
    "                \"Phone\": candidate[\"phone\"],\n",
    "                \"Matched Required Skills\": candidate[\"matched_skills\"],\n",
    "                \"Matched Good-to-Have Skills\": candidate[\"matched_good_to_have_skills\"],\n",
    "                \"Match Percentage\": f\"{candidate['match_percentage']:.2f}%\",\n",
    "            })\n",
    "        \n",
    "        # Display the table\n",
    "        for row in table_data:\n",
    "            print(row)\n",
    "    else:\n",
    "        print(\"No valid candidates found.\")\n",
    "\n",
    "    # Option to save ranked candidates to CSV\n",
    "    output_csv = \"ranked_resumes.csv\"\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"email\", \"phone\", \"match_percentage\", \"matched_skills\", \"skills\", \"filename\"])  # CSV header\n",
    "        for candidate in ranked_candidates:\n",
    "            writer.writerow([  \n",
    "                candidate[\"email\"],\n",
    "                candidate[\"phone\"],\n",
    "                candidate[\"match_percentage\"],\n",
    "                candidate[\"matched_skills\"],\n",
    "                candidate[\"matched_good_to_have_skills\"],\n",
    "                \", \".join(candidate[\"skills\"]),\n",
    "                candidate[\"filename\"]\n",
    "            ])\n",
    "    print(f\"CSV file saved as {output_csv}. You can download it from the filesystem.\")\n",
    "\n",
    "# Example usage:\n",
    "uploaded_files = [open('resume12.pdf', 'rb'), open('sample-resumes_scs-6.pdf', 'rb')]  # Replace with your actual PDF files\n",
    "required_skills = \"Python, SQL, Java\"\n",
    "good_to_have_skills = \"AWS, Docker, git, djnango, javascript\"\n",
    "process_resumes(uploaded_files, required_skills, good_to_have_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6aaa3bc-d8ed-4cac-a027-80c83899f386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing My Resume.pdf...\n",
      "Loading PDF: My Resume.pdf\n",
      "Extracted text from PDF: My Resume.pdf\n",
      "Ravi Gupta\n",
      "AI/ML Enthusiast | Computer Science Engineer\n",
      "Innovative and solution-driven computer science student passionate about artificial intelligence and\n",
      "machine learning. Adept at building and deploying AI-driven applications to solve real-world problems.\n",
      "ravigupta.2140@gmail.com 98342451271\n",
      "EDUCATION SKILLS\n",
      "B.Tech in Computer Science Engineering\n",
      "Programming Languages: Python, Java, C++, JavaScript\n",
      "Indian Institute of Technology, Delhi (IIT Delhi)\n",
      "Frameworks & Libraries: TensorFlow, PyTorch, Scikit-learn,\n",
      "08/2020 - 08/2024, CGPA: 9.2/10\n",
      "Flask\n",
      "Courses\n",
      "Relevant Courses: Machine\n",
      "Cloud Platforms: AWS, Google Cloud, Azure\n",
      "Learning, Artificial\n",
      "Intelligence, Data\n",
      "Tools & Technologies: Git, Docker, Kubernetes, Jupyter,\n",
      "Structures, Deep Learning,\n",
      "REST APIs\n",
      "Cloud Computing\n",
      "Other Skills: Data Analysis, Model Optimization,\n",
      "Debugging\n",
      "WORK EXPERIENCE\n",
      "Machine Learning Intern\n",
      "PERSONAL PROJECTS\n",
      "Workplace/Company\n",
      "05/2023 - 08/2023, 1. AI-Powered Personal Finance Assistant\n",
      "Google AI Research Lab, Bangalore\n",
      "Built an AI assistant using NLP for tracking and analyzing personal\n",
      "Achievements/Tasks expenses.Incorporated ML algorithms to forecast monthly\n",
      "Developed a neural network model for image recognition expenditure trends.Deployed on a Flask backend with a React-\n",
      "based user interface.\n",
      "tasks, improving accuracy by 15% compared to baseline.\n",
      "Implemented scalable pipelines for preprocessing large 2. Object Detection for Autonomous Vehicles\n",
      "datasets using TensorFlow and PyTorch. Developed a YOLO-based real-time object detection system.Trained\n",
      "on large datasets to identify road signs, vehicles, and\n",
      "Collaborated with a team of 10 researchers on optimizing\n",
      "pedestrians.Achieved 85% mAP (mean Average Precision) on\n",
      "hyperparameters using grid search and Bayesian benchmark datasets.\n",
      "optimization.\n",
      "3. Sentiment Analysis Tool for Social Media\n",
      "Software Development Intern Created a tool to analyze and visualize sentiment trends on Twitter\n",
      "using Python.Leveraged APIs to collect data and deployed models\n",
      "Workplace/Company using AWS Lambda for scalability.\n",
      "07/2022 - 08/2022,\n",
      "TCS Innovation Labs, Pune\n",
      "Achievements/Tasks ORGANIZATIONS\n",
      "Designed and implemented a chatbot for automated\n",
      "customer support using Natural Language Processing (NLP) Google Developer Student Club (GDSC) (2022 - Present)\n",
      "techniques. Organized hackathons and technical sessions on advanced ML topics.\n",
      "Integrated AWS services (Lambda, S3) for deployment and\n",
      "storage of models.\n",
      "CERTIFICATES\n",
      "Reduced response time for customer queries by 30% using\n",
      "an optimized inference engine.\n",
      "Deep Learning Specialization by Andrew Ng,\n",
      "Coursera AWS Certified Machine Learning  Specialty\n",
      "TensorFlow Developer Certification\n",
      "LANGUAGES\n",
      "English Hindi\n",
      "Full Professional Proficiency Full Professional Proficiency\n",
      "INTERESTS\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['B.Tech in Computer Science Engineering', 'Programming Languages: Python', ' Java', ' C++', ' JavaScript', 'Indian Institute of Technology', ' Delhi (IIT Delhi)', 'Frameworks & Libraries: TensorFlow', ' PyTorch', ' Scikit-learn', '08/2020 - 08/2024', ' CGPA: 9.2/10', 'Flask', 'Courses', 'Relevant Courses: Machine', 'Cloud Platforms: AWS', ' Google Cloud', ' Azure', 'Learning', ' Artificial', 'Intelligence', ' Data', 'Tools & Technologies: Git', ' Docker', ' Kubernetes', ' Jupyter', 'Structures', ' Deep Learning', 'REST APIs', 'Cloud Computing', 'Other Skills: Data Analysis', ' Model Optimization', 'Debugging', 'WORK ']\n",
      "Cleaning skills: ['B.Tech in Computer Science Engineering', 'Programming Languages: Python', 'Java', 'C++', 'JavaScript', 'Indian Institute of Technology', 'Delhi (IIT Delhi)', 'Frameworks & Libraries: TensorFlow', 'PyTorch', 'Scikit-learn', '08/2020 - 08/2024', 'CGPA: 9.2/10', 'Flask', 'Courses', 'Relevant Courses: Machine', 'Cloud Platforms: AWS', 'Google Cloud', 'Azure', 'Learning', 'Artificial', 'Intelligence', 'Data', 'Tools & Technologies: Git', 'Docker', 'Kubernetes', 'Jupyter', 'Structures', 'Deep Learning', 'REST APIs', 'Cloud Computing', 'Other Skills: Data Analysis', 'Model Optimization', 'Debugging', 'WORK']\n",
      "Cleaned skills: ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work']\n",
      "Extracted information: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'python', 'java', 'javascript'}\n",
      "Skill match percentage: 37.50%\n",
      "Matched Skills: {'python', 'java', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Saving data to resume_data1.csv...\n",
      "Data saved to resume_data1.csv\n",
      "Candidate Data: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work'], 'match_percentage': 37.5}\n",
      "Match Percentage: 37.50%\n",
      "Processing My Resume.pdf...\n",
      "Loading PDF: My Resume.pdf\n",
      "Extracted text from PDF: My Resume.pdf\n",
      "Ravi Gupta\n",
      "AI/ML Enthusiast | Computer Science Engineer\n",
      "Innovative and solution-driven computer science student passionate about artificial intelligence and\n",
      "machine learning. Adept at building and deploying AI-driven applications to solve real-world problems.\n",
      "ravigupta.2140@gmail.com 98342451271\n",
      "EDUCATION SKILLS\n",
      "B.Tech in Computer Science Engineering\n",
      "Programming Languages: Python, Java, C++, JavaScript\n",
      "Indian Institute of Technology, Delhi (IIT Delhi)\n",
      "Frameworks & Libraries: TensorFlow, PyTorch, Scikit-learn,\n",
      "08/2020 - 08/2024, CGPA: 9.2/10\n",
      "Flask\n",
      "Courses\n",
      "Relevant Courses: Machine\n",
      "Cloud Platforms: AWS, Google Cloud, Azure\n",
      "Learning, Artificial\n",
      "Intelligence, Data\n",
      "Tools & Technologies: Git, Docker, Kubernetes, Jupyter,\n",
      "Structures, Deep Learning,\n",
      "REST APIs\n",
      "Cloud Computing\n",
      "Other Skills: Data Analysis, Model Optimization,\n",
      "Debugging\n",
      "WORK EXPERIENCE\n",
      "Machine Learning Intern\n",
      "PERSONAL PROJECTS\n",
      "Workplace/Company\n",
      "05/2023 - 08/2023, 1. AI-Powered Personal Finance Assistant\n",
      "Google AI Research Lab, Bangalore\n",
      "Built an AI assistant using NLP for tracking and analyzing personal\n",
      "Achievements/Tasks expenses.Incorporated ML algorithms to forecast monthly\n",
      "Developed a neural network model for image recognition expenditure trends.Deployed on a Flask backend with a React-\n",
      "based user interface.\n",
      "tasks, improving accuracy by 15% compared to baseline.\n",
      "Implemented scalable pipelines for preprocessing large 2. Object Detection for Autonomous Vehicles\n",
      "datasets using TensorFlow and PyTorch. Developed a YOLO-based real-time object detection system.Trained\n",
      "on large datasets to identify road signs, vehicles, and\n",
      "Collaborated with a team of 10 researchers on optimizing\n",
      "pedestrians.Achieved 85% mAP (mean Average Precision) on\n",
      "hyperparameters using grid search and Bayesian benchmark datasets.\n",
      "optimization.\n",
      "3. Sentiment Analysis Tool for Social Media\n",
      "Software Development Intern Created a tool to analyze and visualize sentiment trends on Twitter\n",
      "using Python.Leveraged APIs to collect data and deployed models\n",
      "Workplace/Company using AWS Lambda for scalability.\n",
      "07/2022 - 08/2022,\n",
      "TCS Innovation Labs, Pune\n",
      "Achievements/Tasks ORGANIZATIONS\n",
      "Designed and implemented a chatbot for automated\n",
      "customer support using Natural Language Processing (NLP) Google Developer Student Club (GDSC) (2022 - Present)\n",
      "techniques. Organized hackathons and technical sessions on advanced ML topics.\n",
      "Integrated AWS services (Lambda, S3) for deployment and\n",
      "storage of models.\n",
      "CERTIFICATES\n",
      "Reduced response time for customer queries by 30% using\n",
      "an optimized inference engine.\n",
      "Deep Learning Specialization by Andrew Ng,\n",
      "Coursera AWS Certified Machine Learning  Specialty\n",
      "TensorFlow Developer Certification\n",
      "LANGUAGES\n",
      "English Hindi\n",
      "Full Professional Proficiency Full Professional Proficiency\n",
      "INTERESTS\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracting skills...\n",
      "Raw skills extracted: ['B.Tech in Computer Science Engineering', 'Programming Languages: Python', ' Java', ' C++', ' JavaScript', 'Indian Institute of Technology', ' Delhi (IIT Delhi)', 'Frameworks & Libraries: TensorFlow', ' PyTorch', ' Scikit-learn', '08/2020 - 08/2024', ' CGPA: 9.2/10', 'Flask', 'Courses', 'Relevant Courses: Machine', 'Cloud Platforms: AWS', ' Google Cloud', ' Azure', 'Learning', ' Artificial', 'Intelligence', ' Data', 'Tools & Technologies: Git', ' Docker', ' Kubernetes', ' Jupyter', 'Structures', ' Deep Learning', 'REST APIs', 'Cloud Computing', 'Other Skills: Data Analysis', ' Model Optimization', 'Debugging', 'WORK ']\n",
      "Cleaning skills: ['B.Tech in Computer Science Engineering', 'Programming Languages: Python', 'Java', 'C++', 'JavaScript', 'Indian Institute of Technology', 'Delhi (IIT Delhi)', 'Frameworks & Libraries: TensorFlow', 'PyTorch', 'Scikit-learn', '08/2020 - 08/2024', 'CGPA: 9.2/10', 'Flask', 'Courses', 'Relevant Courses: Machine', 'Cloud Platforms: AWS', 'Google Cloud', 'Azure', 'Learning', 'Artificial', 'Intelligence', 'Data', 'Tools & Technologies: Git', 'Docker', 'Kubernetes', 'Jupyter', 'Structures', 'Deep Learning', 'REST APIs', 'Cloud Computing', 'Other Skills: Data Analysis', 'Model Optimization', 'Debugging', 'WORK']\n",
      "Cleaned skills: ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work']\n",
      "Extracted information: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work']}\n",
      "Evaluating skills... Required skills: Python, SQL, React, Django, Java, JavaScript, HTML, CSS\n",
      "Matched skills: {'python', 'java', 'javascript'}\n",
      "Skill match percentage: 37.50%\n",
      "Matched Skills: {'python', 'java', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Saving data to resume_data1.csv...\n",
      "Data saved to resume_data1.csv\n",
      "Candidate Data: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging', 'work'], 'match_percentage': 37.5}\n",
      "Match Percentage: 37.50%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    print(f\"Loading PDF: {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "    print(f\"Extracted text from PDF: {file_path}\\n{text}\")\n",
    "    return text\n",
    "\n",
    "import re\n",
    "import csv\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    print(f\"Loading PDF: {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "    print(f\"Extracted text from PDF: {file_path}\\n{text}\")\n",
    "    return text\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    print(\"Extracting skills...\")\n",
    "    skills_match = re.search(r\"SKILLS\\s*([\\s\\S]*?)(?=(COURSEWORK|EXPERIENCE|EDUCATION|PROJECTS|$))\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)#bullet operators unicode\n",
    "        print(f\"Raw skills extracted: {skills}\")\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    print(\"No skills section found.\")\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean and normalize extracted skills.\"\"\"\n",
    "    print(f\"Cleaning skills: {raw_skills}\")\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"^\\s*-?\\s*\", \"\", skill)\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", cleaned_skill).strip()# text enclosed in parenthsis\n",
    "        \n",
    "        words = re.split(r\"[,\\s:/;]+\", cleaned_skill)\n",
    "        cleaned.extend(word.strip() for word in words if word.strip())\n",
    "    # Remove duplicates and normalize case\n",
    "    cleaned_skills = list(dict.fromkeys(word.lower() for word in cleaned))\n",
    "    print(f\"Cleaned skills: {cleaned_skills}\")\n",
    "    return cleaned_skills\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    print(\"Extracting key information (email, phone, etc.)...\")\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    result_data = {}\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key != \"skills\":\n",
    "            result_data[key] = value.group(0) if value else \"Not available\"\n",
    "        else:\n",
    "            result_data[key] = value\n",
    "    print(f\"Extracted information: {result_data}\")\n",
    "    return result_data\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    print(f\"Saving data to {file_name}...\")\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:  # Check if the file is empty to write headers\n",
    "            writer.writerow(data.keys())  # Write headers(\"name\", \"email\", \"phone\")\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    print(f\"Evaluating skills... Required skills: {required_skills}\")\n",
    "    candidate_set = set(map(str.lower, candidate_skills))\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = candidate_set.intersection(required_set)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    print(f\"Matched skills: {matched_skills}\")\n",
    "    print(f\"Skill match percentage: {match_percentage:.2f}%\")\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "def process_single_pdf(file_path, required_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "    # Output the matched skills and percentage\n",
    "    print(f\"Matched Skills: {matched_skills}\")\n",
    "    print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "    # Store the candidate data with match percentage for ranking\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"match_percentage\"] = match_percentage\n",
    "\n",
    "    # Save extracted data to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "    return candidate_data, match_percentage\n",
    "\n",
    "# Example usage for one resume:\n",
    "#file_path = \"John Doe.pdf\"# Replace with the path to the resume PDF\n",
    "#file_path = \"computer-science-resume-example.pdf\"\n",
    "file_path = \"My Resume.pdf\"\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process a single PDF resume\n",
    "candidate_data, match_percentage = process_single_pdf(file_path, required_skills)\n",
    "\n",
    "# Output the result for the candidate\n",
    "print(f\"Candidate Data: {candidate_data}\")\n",
    "print(f\"Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    print(\"Extracting key information (email, phone, etc.)...\")\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    result_data = {}\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key != \"skills\":\n",
    "            result_data[key] = value.group(0) if value else \"Not available\"\n",
    "        else:\n",
    "            result_data[key] = value\n",
    "    print(f\"Extracted information: {result_data}\")\n",
    "    return result_data\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    print(f\"Saving data to {file_name}...\")\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:  # Check if the file is empty to write headers\n",
    "            writer.writerow(data.keys())  # Write headers(\"name\", \"email\", \"phone\")\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "\n",
    "\n",
    "def process_single_pdf(file_path, required_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "    # Output the matched skills and percentage\n",
    "    print(f\"Matched Skills: {matched_skills}\")\n",
    "    print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "    # Store the candidate data with match percentage for ranking\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"match_percentage\"] = match_percentage\n",
    "\n",
    "    # Save extracted data to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "    return candidate_data, match_percentage\n",
    "\n",
    "# Example usage for one resume:\n",
    "#file_path = \"John Doe.pdf\"# Replace with the path to the resume PDF\n",
    "#file_path = \"computer-science-resume-example.pdf\"\n",
    "file_path = \"My Resume.pdf\"\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process a single PDF resume\n",
    "candidate_data, match_percentage = process_single_pdf(file_path, required_skills)\n",
    "\n",
    "# Output the result for the candidate\n",
    "print(f\"Candidate Data: {candidate_data}\")\n",
    "print(f\"Match Percentage: {match_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4ff1380-0718-48b7-8cc3-14c09d77cc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing My Resume.pdf...\n",
      "Loading PDF: My Resume.pdf\n",
      "Extracted text from PDF: My Resume.pdf\n",
      "Ravi Gupta\n",
      "AI/ML Enthusiast | Computer Science Engineer\n",
      "Innovative and solution-driven computer science student passionate about artificial intelligence and\n",
      "machine learning. Adept at building and deploying AI-driven applications to solve real-world problems.\n",
      "ravigupta.2140@gmail.com 98342451271\n",
      "EDUCATION SKILLS\n",
      "B.Tech in Computer Science Engineering\n",
      "Programming Languages: Python, Java, C++, JavaScript\n",
      "Indian Institute of Technology, Delhi (IIT Delhi)\n",
      "Frameworks & Libraries: TensorFlow, PyTorch, Scikit-learn,\n",
      "08/2020 - 08/2024, CGPA: 9.2/10\n",
      "Flask\n",
      "Courses\n",
      "Relevant Courses: Machine\n",
      "Cloud Platforms: AWS, Google Cloud, Azure\n",
      "Learning, Artificial\n",
      "Intelligence, Data\n",
      "Tools & Technologies: Git, Docker, Kubernetes, Jupyter,\n",
      "Structures, Deep Learning,\n",
      "REST APIs\n",
      "Cloud Computing\n",
      "Other Skills: Data Analysis, Model Optimization,\n",
      "Debugging\n",
      "WORK EXPERIENCE\n",
      "Machine Learning Intern\n",
      "PERSONAL PROJECTS\n",
      "Workplace/Company\n",
      "05/2023 - 08/2023, 1. AI-Powered Personal Finance Assistant\n",
      "Google AI Research Lab, Bangalore\n",
      "Built an AI assistant using NLP for tracking and analyzing personal\n",
      "Achievements/Tasks expenses.Incorporated ML algorithms to forecast monthly\n",
      "Developed a neural network model for image recognition expenditure trends.Deployed on a Flask backend with a React-\n",
      "based user interface.\n",
      "tasks, improving accuracy by 15% compared to baseline.\n",
      "Implemented scalable pipelines for preprocessing large 2. Object Detection for Autonomous Vehicles\n",
      "datasets using TensorFlow and PyTorch. Developed a YOLO-based real-time object detection system.Trained\n",
      "on large datasets to identify road signs, vehicles, and\n",
      "Collaborated with a team of 10 researchers on optimizing\n",
      "pedestrians.Achieved 85% mAP (mean Average Precision) on\n",
      "hyperparameters using grid search and Bayesian benchmark datasets.\n",
      "optimization.\n",
      "3. Sentiment Analysis Tool for Social Media\n",
      "Software Development Intern Created a tool to analyze and visualize sentiment trends on Twitter\n",
      "using Python.Leveraged APIs to collect data and deployed models\n",
      "Workplace/Company using AWS Lambda for scalability.\n",
      "07/2022 - 08/2022,\n",
      "TCS Innovation Labs, Pune\n",
      "Achievements/Tasks ORGANIZATIONS\n",
      "Designed and implemented a chatbot for automated\n",
      "customer support using Natural Language Processing (NLP) Google Developer Student Club (GDSC) (2022 - Present)\n",
      "techniques. Organized hackathons and technical sessions on advanced ML topics.\n",
      "Integrated AWS services (Lambda, S3) for deployment and\n",
      "storage of models.\n",
      "CERTIFICATES\n",
      "Reduced response time for customer queries by 30% using\n",
      "an optimized inference engine.\n",
      "Deep Learning Specialization by Andrew Ng,\n",
      "Coursera AWS Certified Machine Learning  Specialty\n",
      "TensorFlow Developer Certification\n",
      "LANGUAGES\n",
      "English Hindi\n",
      "Full Professional Proficiency Full Professional Proficiency\n",
      "INTERESTS\n",
      "Extracting key information (email, phone, etc.)...\n",
      "Extracted information: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging']}\n",
      "Matched Skills: {'python', 'java', 'javascript'}\n",
      "Skill Match Percentage: 37.50%\n",
      "Saving data to resume_data1.csv...\n",
      "Data saved to resume_data1.csv\n",
      "Candidate Data: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging'], 'match_percentage': 37.5}\n",
      "Match Percentage: 37.50%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    print(f\"Loading PDF: {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "    print(f\"Extracted text from PDF: {file_path}\\n{text}\")\n",
    "    return text\n",
    "\n",
    "import re\n",
    "import csv\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    print(f\"Loading PDF: {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "    print(f\"Extracted text from PDF: {file_path}\\n{text}\")\n",
    "    return text\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    # Match the SKILLS section up to the next heading or end of text\n",
    "    skills_match = re.search(r\"SKILLS\\s*([\\s\\S]*?)(?=(WORK EXPERIENCE|PERSONAL PROJECTS|$))\", text, re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        # Split by bullets, commas, or whitespace and clean the skills\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    return []\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean, normalize, and correct extracted skills.\"\"\"\n",
    "    typo_corrections = {\n",
    "        \"pyhton\": \"python\",  # Fix common typos\n",
    "    }\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        # Remove extra symbols and normalize text\n",
    "        cleaned_skill = re.sub(r\"^\\s*-?\\s*\", \"\", skill)\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", cleaned_skill).strip()\n",
    "        cleaned_skill = typo_corrections.get(cleaned_skill.lower(), cleaned_skill.lower())\n",
    "        words = re.split(r\"[,\\s:/;]+\", cleaned_skill)\n",
    "        cleaned.extend(word for word in words if word)\n",
    "    # Remove duplicates\n",
    "    return list(dict.fromkeys(cleaned))\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    from rapidfuzz import fuzz  # Use fuzzy matching\n",
    "    candidate_set = set(candidate_skills)\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = set()\n",
    "    for required in required_set:\n",
    "        for candidate in candidate_set:\n",
    "            # Fuzzy match threshold for similar skills\n",
    "            if fuzz.ratio(required, candidate) > 80:\n",
    "                matched_skills.add(candidate)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    print(\"Extracting key information (email, phone, etc.)...\")\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "    }\n",
    "    result_data = {}\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key != \"skills\":\n",
    "            result_data[key] = value.group(0) if value else \"Not available\"\n",
    "        else:\n",
    "            result_data[key] = value\n",
    "    print(f\"Extracted information: {result_data}\")\n",
    "    return result_data\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    print(f\"Saving data to {file_name}...\")\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:  # Check if the file is empty to write headers\n",
    "            writer.writerow(data.keys())  # Write headers(\"name\", \"email\", \"phone\")\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "\n",
    "\n",
    "def process_single_pdf(file_path, required_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "    # Output the matched skills and percentage\n",
    "    print(f\"Matched Skills: {matched_skills}\")\n",
    "    print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "    # Store the candidate data with match percentage for ranking\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"match_percentage\"] = match_percentage\n",
    "\n",
    "    # Save extracted data to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "    return candidate_data, match_percentage\n",
    "\n",
    "# Example usage for one resume:\n",
    "#file_path = \"John Doe.pdf\"# Replace with the path to the resume PDF\n",
    "#file_path = \"computer-science-resume-example.pdf\"\n",
    "file_path = \"My Resume.pdf\"\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process a single PDF resume\n",
    "candidate_data, match_percentage = process_single_pdf(file_path, required_skills)\n",
    "\n",
    "# Output the result for the candidate\n",
    "print(f\"Candidate Data: {candidate_data}\")\n",
    "print(f\"Match Percentage: {match_percentage:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23b85bef-2aa6-4e75-8193-8965f0e89cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (3.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a58a94d6-3202-4c57-9fe2-c53a951dabd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e356b38-b712-41fe-b5b7-ff7307b6da5d",
   "metadata": {},
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "import csv\n",
    "import pdfplumber\n",
    "\n",
    "# Use Hugging Face pipeline for NER (Named Entity Recognition)\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", aggregation_strategy=\"simple\")\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    print(f\"Loading PDF: {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "    print(f\"Extracted text from PDF: {file_path}\\n{text}\")\n",
    "    return text\n",
    "\n",
    "def extract_skills_using_ner(text):\n",
    "    \"\"\"Extract skills from the resume text using Hugging Face's NER pipeline.\"\"\"\n",
    "    print(\"Extracting skills using NER...\")\n",
    "    entities = ner_pipeline(text)\n",
    "    \n",
    "    skills = []\n",
    "    for entity in entities:\n",
    "        if entity['entity_group'] == 'MISC':  # We assume skills are recognized as 'MISC'\n",
    "            skills.append(entity['word'])\n",
    "    \n",
    "    # Clean up extracted skills\n",
    "    cleaned_skills = clean_skills(skills)\n",
    "    return cleaned_skills\n",
    "\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean, normalize, and correct extracted skills.\"\"\"\n",
    "    typo_corrections = {\n",
    "        \"pyhton\": \"python\",  # Fix common typos\n",
    "    }\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"^\\s*-?\\s*\", \"\", skill)\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", cleaned_skill).strip()\n",
    "        cleaned_skill = typo_corrections.get(cleaned_skill.lower(), cleaned_skill.lower())\n",
    "        cleaned.append(cleaned_skill)\n",
    "    return list(dict.fromkeys(cleaned))  # Remove duplicates\n",
    "\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    from rapidfuzz import fuzz  # Use fuzzy matching\n",
    "    candidate_set = set(candidate_skills)\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = set()\n",
    "    for required in required_set:\n",
    "        for candidate in candidate_set:\n",
    "            if fuzz.ratio(required, candidate) > 80:\n",
    "                matched_skills.add(candidate)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill extraction.\"\"\"\n",
    "    print(\"Extracting key information (email, phone, etc.)...\")\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills_using_ner(text),\n",
    "    }\n",
    "    result_data = {}\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if key != \"skills\":\n",
    "            result_data[key] = value.group(0) if value else \"Not available\"\n",
    "        else:\n",
    "            result_data[key] = value\n",
    "    print(f\"Extracted information: {result_data}\")\n",
    "    return result_data\n",
    "\n",
    "def save_to_csv(data, file_name=\"resume_data1.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    print(f\"Saving data to {file_name}...\")\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:  # Check if the file is empty to write headers\n",
    "            writer.writerow(data.keys())  # Write headers(\"name\", \"email\", \"phone\")\n",
    "        writer.writerow(data.values())  # Write values\n",
    "    print(f\"Data saved to {file_name}\")\n",
    "\n",
    "def process_single_pdf(file_path, required_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "\n",
    "    # Output the matched skills and percentage\n",
    "    print(f\"Matched Skills: {matched_skills}\")\n",
    "    print(f\"Skill Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "    # Store the candidate data with match percentage for ranking\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"match_percentage\"] = match_percentage\n",
    "\n",
    "    # Save extracted data to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "    return candidate_data, match_percentage\n",
    "\n",
    "# Example usage for one resume:\n",
    "file_path = \"My Resume.pdf\"\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process a single PDF resume\n",
    "candidate_data, match_percentage = process_single_pdf(file_path, required_skills)\n",
    "\n",
    "# Output the result for the candidate\n",
    "print(f\"Candidate Data: {candidate_data}\")\n",
    "print(f\"Match Percentage: {match_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b93a9c6-7289-4474-8c0a-45f3e50dc8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (4.48.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "081e5d15-d62b-4d7c-9176-b160e1138bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Extracted Resume Data -------------\n",
      "Candidate Data: {'email': 'ravigupta.2140@gmail.com', 'phone': '98342451271', 'skills': ['b.tech', 'in', 'computer', 'science', 'engineering', 'programming', 'languages', 'python', 'java', 'c++', 'javascript', 'indian', 'institute', 'of', 'technology', 'delhi', 'frameworks', '&', 'libraries', 'tensorflow', 'pytorch', 'scikit-learn', '08', '2020', '-', '2024', 'cgpa', '9.2', '10', 'flask', 'courses', 'relevant', 'machine', 'cloud', 'platforms', 'aws', 'google', 'azure', 'learning', 'artificial', 'intelligence', 'data', 'tools', 'technologies', 'git', 'docker', 'kubernetes', 'jupyter', 'structures', 'deep', 'rest', 'apis', 'computing', 'other', 'skills', 'analysis', 'model', 'optimization', 'debugging'], 'experience': [], 'education': [], 'match_percentage': 37.5}\n",
      "Match Percentage: 37.50%\n",
      "------------- Education Data -------------\n",
      "Education: []\n",
      "------------- Total Experience -------------\n",
      "Total Experience: 0 years, 0 months\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pdfplumber\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# Helper function to calculate months difference\n",
    "def calculate_months(start_date, end_date):\n",
    "    \"\"\"Calculates the number of months between two dates.\"\"\"\n",
    "    return (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)\n",
    "\n",
    "# Function to load and extract text from PDF\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Extracts text from the PDF.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            text = ''.join(page.extract_text() for page in pdf.pages)\n",
    "    return text\n",
    "\n",
    "# Extract skills from text based on SKILLS section\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extracts skills from the text based on the 'Skills' section.\"\"\"\n",
    "    skills_match = re.search(r\"SKILLS\\s*([\\s\\S]*?)(?=(WORK EXPERIENCE|PERSONAL PROJECTS|EDUCATION|$))\", text, re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        skills_text = skills_match.group(1)\n",
    "        skills = re.split(r\"[\\u2022\\n,]+\", skills_text)\n",
    "        return clean_skills([skill.strip() for skill in skills if skill.strip()])\n",
    "    return []\n",
    "\n",
    "# Clean extracted skills\n",
    "def clean_skills(raw_skills):\n",
    "    \"\"\"Clean, normalize, and correct extracted skills.\"\"\"\n",
    "    typo_corrections = {\n",
    "        \"pyhton\": \"python\",  # Fix common typos\n",
    "    }\n",
    "    cleaned = []\n",
    "    for skill in raw_skills:\n",
    "        cleaned_skill = re.sub(r\"^\\s*-?\\s*\", \"\", skill)\n",
    "        cleaned_skill = re.sub(r\"\\(.*?\\)\", \"\", cleaned_skill).strip()\n",
    "        cleaned_skill = typo_corrections.get(cleaned_skill.lower(), cleaned_skill.lower())\n",
    "        words = re.split(r\"[,\\s:/;]+\", cleaned_skill)\n",
    "        cleaned.extend(word for word in words if word)\n",
    "    cleaned = list(dict.fromkeys(cleaned))\n",
    "    return cleaned\n",
    "\n",
    "# Function to evaluate skills using fuzzy matching\n",
    "def evaluate_skills(candidate_skills, required_skills):\n",
    "    \"\"\"Matches candidate's skills with required skills.\"\"\"\n",
    "    candidate_set = set(candidate_skills)\n",
    "    required_set = set(map(str.lower, required_skills.split(\", \")))\n",
    "    matched_skills = set()\n",
    "    for required in required_set:\n",
    "        for candidate in candidate_set:\n",
    "            if fuzz.ratio(required, candidate) > 80:\n",
    "                matched_skills.add(candidate)\n",
    "    match_percentage = (len(matched_skills) / len(required_set)) * 100 if required_set else 0\n",
    "    return matched_skills, match_percentage\n",
    "\n",
    "# Extract work experience from text\n",
    "def extract_experience(text):\n",
    "    \"\"\"Extracts work experience (roles, start, and end dates) from the resume.\"\"\"\n",
    "    experiences = []\n",
    "    experience_pattern = re.compile(r\"(?:WORK EXPERIENCE|EXPERIENCE)[\\s\\S]+?(?=(EDUCATION|SKILLS|$))\", re.IGNORECASE)\n",
    "    experience_section = experience_pattern.search(text)\n",
    "    if experience_section:\n",
    "        experience_text = experience_section.group(0)\n",
    "        role_pattern = re.compile(r\"([A-Za-z\\s]+)\\s+(\\d{4}-\\d{2}-\\d{2})\\s*[-]?\\s*(\\d{4}-\\d{2}-\\d{2}|Present)\", re.IGNORECASE)\n",
    "        roles = role_pattern.findall(experience_text)\n",
    "        for role in roles:\n",
    "            role_title = role[0].strip()\n",
    "            start_date_str = role[1]\n",
    "            end_date_str = role[2] if role[2].lower() != \"present\" else datetime.now().strftime('%Y-%m-%d')\n",
    "            experiences.append({\n",
    "                \"role\": role_title,\n",
    "                \"start\": start_date_str,\n",
    "                \"end\": end_date_str\n",
    "            })\n",
    "    return experiences\n",
    "\n",
    "# Extract education details\n",
    "def extract_education(text):\n",
    "    \"\"\"Extracts education details (degree, university, year, percentage).\"\"\"\n",
    "    education_data = []\n",
    "    education_pattern = re.compile(r\"EDUCATION[\\s\\S]+?(?=(WORK EXPERIENCE|SKILLS|$))\", re.IGNORECASE)\n",
    "    education_section = education_pattern.search(text)\n",
    "    if education_section:\n",
    "        education_text = education_section.group(0)\n",
    "        edu_pattern = re.compile(r\"([A-Za-z\\s]+)\\s+(\\d{4})\\s+([-+]?\\d*\\.\\d+|\\d+)%?\", re.IGNORECASE)\n",
    "        education_details = edu_pattern.findall(education_text)\n",
    "        for edu in education_details:\n",
    "            degree = edu[0].strip()\n",
    "            year = edu[1].strip()\n",
    "            percentage = edu[2].strip()\n",
    "            education_data.append({\n",
    "                \"degree\": degree,\n",
    "                \"year\": year,\n",
    "                \"percentage\": percentage\n",
    "            })\n",
    "    return education_data\n",
    "\n",
    "# Function to extract key information (email, phone, etc.) from text\n",
    "def extract_info(text):\n",
    "    \"\"\"Extracts key information (email, phone, etc.) and invokes skill and experience extraction.\"\"\"\n",
    "    data = {\n",
    "        \"email\": re.search(r\"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\", text),\n",
    "        \"phone\": re.search(r\"(\\+?\\d{1,4}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\", text),\n",
    "        \"skills\": extract_skills(text),\n",
    "        \"experience\": extract_experience(text),\n",
    "        \"education\": extract_education(text)\n",
    "    }\n",
    "    result_data = {}\n",
    "    for key, value in data.items():\n",
    "        if key != \"skills\" and key != \"experience\" and key != \"education\":\n",
    "            result_data[key] = value.group(0) if value else \"Not available\"\n",
    "        else:\n",
    "            result_data[key] = value\n",
    "    return result_data\n",
    "\n",
    "# Function to save extracted data to CSV\n",
    "def save_to_csv(data, file_name=\"resume_data.csv\"):\n",
    "    \"\"\"Saves extracted data to CSV.\"\"\"\n",
    "    with open(file_name, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:  # Write headers if file is empty\n",
    "            writer.writerow(data.keys())\n",
    "        writer.writerow(data.values())\n",
    "\n",
    "# Function to process a single PDF resume and extract information\n",
    "def process_single_pdf(file_path, required_skills):\n",
    "    \"\"\"Processes a single PDF resume file.\"\"\"\n",
    "    # Load and parse the resume\n",
    "    text = load_pdf(file_path)\n",
    "    data = extract_info(text)\n",
    "\n",
    "    # Evaluate candidate skills\n",
    "    matched_skills, match_percentage = evaluate_skills(data[\"skills\"], required_skills)\n",
    "    \n",
    "    # Output matched skills and percentage\n",
    "    candidate_data = data.copy()\n",
    "    candidate_data[\"match_percentage\"] = match_percentage\n",
    "\n",
    "    # Save extracted data to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "    return candidate_data, match_percentage\n",
    "\n",
    "# Function to calculate total experience from work experiences\n",
    "def calculate_total_experience(experiences):\n",
    "    \"\"\"Calculates the total work experience in months from a list of experiences.\"\"\"\n",
    "    total_months = 0\n",
    "    for exp in experiences:\n",
    "        start_date = datetime.strptime(exp[\"start\"], \"%Y-%m-%d\")\n",
    "        end_date = datetime.strptime(exp[\"end\"], \"%Y-%m-%d\")\n",
    "        total_months += calculate_months(start_date, end_date)\n",
    "    \n",
    "    years = total_months // 12\n",
    "    months = total_months % 12\n",
    "    return years, months\n",
    "\n",
    "# Example usage\n",
    "file_path = \"My Resume.pdf\"\n",
    "required_skills = \"Python, SQL, React, Django, Java, JavaScript, HTML, CSS\"  # Example required skills\n",
    "\n",
    "# Process resume PDF\n",
    "candidate_data, match_percentage = process_single_pdf(file_path, required_skills)\n",
    "\n",
    "# Process work experience dates\n",
    "years, months = calculate_total_experience(candidate_data[\"experience\"])\n",
    "\n",
    "# Print everything\n",
    "print(\"------------- Extracted Resume Data -------------\")\n",
    "print(f\"Candidate Data: {candidate_data}\")\n",
    "print(f\"Match Percentage: {match_percentage:.2f}%\")\n",
    "print(\"------------- Education Data -------------\")\n",
    "print(f\"Education: {candidate_data['education']}\")\n",
    "print(\"------------- Total Experience -------------\")\n",
    "print(f\"Total Experience: {years} years, {months} months\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f93e4fa-5138-4d95-8b04-3a072128c62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Details:\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6664eb-09f8-4969-af64-a7c64ea061f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
